{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFDaSA7OnN9U",
        "outputId": "ac54b85b-1048-40f1-82a9-16047d7dd70c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting web3\n",
            "  Downloading web3-7.12.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting eth-account\n",
            "  Downloading eth_account-0.13.7-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting eth-abi>=5.0.1 (from web3)\n",
            "  Downloading eth_abi-5.2.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting eth-hash>=0.5.1 (from eth-hash[pycryptodome]>=0.5.1->web3)\n",
            "  Downloading eth_hash-0.7.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting eth-typing>=5.0.0 (from web3)\n",
            "  Downloading eth_typing-5.2.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting eth-utils>=5.0.0 (from web3)\n",
            "  Downloading eth_utils-5.3.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting hexbytes>=1.2.0 (from web3)\n",
            "  Downloading hexbytes-1.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: aiohttp>=3.7.4.post0 in /usr/local/lib/python3.11/dist-packages (from web3) (3.11.15)\n",
            "Requirement already satisfied: pydantic>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from web3) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from web3) (4.14.1)\n",
            "Collecting types-requests>=2.0.0 (from web3)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: websockets<16.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from web3) (15.0.1)\n",
            "Collecting pyunormalize>=15.0.0 (from web3)\n",
            "  Downloading pyunormalize-16.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting bitarray>=2.4.0 (from eth-account)\n",
            "  Downloading bitarray-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Collecting eth-keyfile<0.9.0,>=0.7.0 (from eth-account)\n",
            "  Downloading eth_keyfile-0.8.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting eth-keys>=0.4.0 (from eth-account)\n",
            "  Downloading eth_keys-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting eth-rlp>=2.1.0 (from eth-account)\n",
            "  Downloading eth_rlp-2.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting rlp>=1.0.0 (from eth-account)\n",
            "  Downloading rlp-4.1.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting ckzg>=2.0.0 (from eth-account)\n",
            "  Downloading ckzg-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (887 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7.4.post0->web3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7.4.post0->web3) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7.4.post0->web3) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7.4.post0->web3) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7.4.post0->web3) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7.4.post0->web3) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7.4.post0->web3) (1.20.1)\n",
            "Collecting parsimonious<0.11.0,>=0.10.0 (from eth-abi>=5.0.1->web3)\n",
            "  Downloading parsimonious-0.10.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pycryptodome<4,>=3.6.6 (from eth-hash[pycryptodome]>=0.5.1->web3)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting cytoolz>=0.10.1 (from eth-utils>=5.0.0->web3)\n",
            "  Downloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->web3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->web3) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.0->web3) (0.4.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from cytoolz>=0.10.1->eth-utils>=5.0.0->web3) (0.12.1)\n",
            "Requirement already satisfied: regex>=2022.3.15 in /usr/local/lib/python3.11/dist-packages (from parsimonious<0.11.0,>=0.10.0->eth-abi>=5.0.1->web3) (2024.11.6)\n",
            "Downloading web3-7.12.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eth_account-0.13.7-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.5/587.5 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitarray-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ckzg-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eth_abi-5.2.0-py3-none-any.whl (28 kB)\n",
            "Downloading eth_hash-0.7.1-py3-none-any.whl (8.0 kB)\n",
            "Downloading eth_keyfile-0.8.1-py3-none-any.whl (7.5 kB)\n",
            "Downloading eth_keys-0.7.0-py3-none-any.whl (20 kB)\n",
            "Downloading eth_rlp-2.2.0-py3-none-any.whl (4.4 kB)\n",
            "Downloading eth_typing-5.2.1-py3-none-any.whl (19 kB)\n",
            "Downloading eth_utils-5.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hexbytes-1.3.1-py3-none-any.whl (5.1 kB)\n",
            "Downloading pyunormalize-16.0.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rlp-4.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Downloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parsimonious-0.10.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ckzg, bitarray, types-requests, pyunormalize, pycryptodome, parsimonious, hexbytes, eth-typing, eth-hash, cytoolz, eth-utils, rlp, eth-keys, eth-abi, eth-rlp, eth-keyfile, eth-account, web3\n",
            "Successfully installed bitarray-3.5.2 ckzg-2.1.1 cytoolz-1.0.1 eth-abi-5.2.0 eth-account-0.13.7 eth-hash-0.7.1 eth-keyfile-0.8.1 eth-keys-0.7.0 eth-rlp-2.2.0 eth-typing-5.2.1 eth-utils-5.3.0 hexbytes-1.3.1 parsimonious-0.10.0 pycryptodome-3.23.0 pyunormalize-16.0.0 rlp-4.1.0 types-requests-2.32.4.20250611 web3-7.12.1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install web3 eth-account requests plotly scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wallet Risk Scoring from Compound Protocol Data\n",
        "# Advanced On-Chain Analytics for DeFi Risk Assessment\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data visualization and analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "from web3 import Web3\n",
        "import time\n",
        "\n",
        "print(\"🚀 Advanced Wallet Risk Scoring System\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    # Free RPC endpoints (you can replace with your own)\n",
        "    RPC_URLS = [\n",
        "        \"https://eth-mainnet.public.blastapi.io\",\n",
        "        \"https://rpc.ankr.com/eth\",\n",
        "        \"https://ethereum.publicnode.com\",\n",
        "    ]\n",
        "\n",
        "    # Compound V2 Contract Addresses\n",
        "    COMPOUND_V2_COMPTROLLER = \"0x3d9819210A31b4961b30EF54bE2aeD79B9c9Cd3B\"\n",
        "\n",
        "    # Compound V2 cToken Addresses (major markets)\n",
        "    CTOKENS = {\n",
        "        \"cETH\": \"0x4Ddc2D193948926D02f9B1fE9e1daa0718270ED5\",\n",
        "        \"cDAI\": \"0x5d3a536E4D6DbD6114cc1Ead35777bAb948E3643\",\n",
        "        \"cUSDC\": \"0x39AA39c021dfbaE8faC545936693aC917d5E7563\",\n",
        "        \"cUSDT\": \"0xf650C3d88D12dB855b8bf7D11Be6C55A4e07dCC9\",\n",
        "        \"cWBTC\": \"0xC11b1268C1A384e55C48c2391d8d480264A3A7F4\",\n",
        "        \"cUNI\": \"0x35A18000230DA775CAc24873d00Ff85BccdeD550\",\n",
        "        \"cLINK\": \"0xFAce851a4921ce59e912d19329929CE6da6EB0c7\",\n",
        "    }\n",
        "\n",
        "    # Risk scoring weights\n",
        "    RISK_WEIGHTS = {\n",
        "        'liquidation_risk': 0.25,\n",
        "        'concentration_risk': 0.20,\n",
        "        'volatility_risk': 0.15,\n",
        "        'leverage_risk': 0.15,\n",
        "        'activity_risk': 0.10,\n",
        "        'duration_risk': 0.10,\n",
        "        'correlation_risk': 0.05\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Enhanced Web3 Connection Manager\n",
        "class Web3Manager:\n",
        "    def __init__(self):\n",
        "        self.w3 = None\n",
        "        self.connect()\n",
        "\n",
        "    def connect(self):\n",
        "        for rpc_url in config.RPC_URLS:\n",
        "            try:\n",
        "                w3 = Web3(Web3.HTTPProvider(rpc_url))\n",
        "                if w3.is_connected():\n",
        "                    self.w3 = w3\n",
        "                    print(f\"✅ Connected to Ethereum via {rpc_url}\")\n",
        "                    return\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Failed to connect to {rpc_url}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not self.w3:\n",
        "            raise Exception(\"Failed to connect to any RPC endpoint\")\n",
        "\n",
        "    def get_transaction_count(self, address):\n",
        "        try:\n",
        "            return self.w3.eth.get_transaction_count(address)\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def get_balance(self, address):\n",
        "        try:\n",
        "            return self.w3.eth.get_balance(address)\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "web3_manager = Web3Manager()\n",
        "\n",
        "# Advanced Data Collector for Compound Protocol\n",
        "class CompoundDataCollector:\n",
        "    def __init__(self):\n",
        "        self.base_url = \"https://api.etherscan.io/api\"\n",
        "        self.api_key = \"YourApiKeyHere\"  # Replace with actual API key for production\n",
        "\n",
        "    def get_wallet_transactions(self, wallet_address, max_transactions=1000):\n",
        "        \"\"\"Fetch transaction history for a wallet\"\"\"\n",
        "        print(f\"📊 Analyzing wallet: {wallet_address}\")\n",
        "\n",
        "        # Simulate fetching data (replace with actual API calls in production)\n",
        "        transactions = self._simulate_compound_transactions(wallet_address)\n",
        "        return transactions\n",
        "\n",
        "    def _simulate_compound_transactions(self, wallet_address):\n",
        "        \"\"\"Simulate Compound protocol interactions for demonstration\"\"\"\n",
        "        np.random.seed(int(wallet_address[-4:], 16))  # Deterministic randomization\n",
        "\n",
        "        transactions = []\n",
        "        base_date = datetime.now() - timedelta(days=365)\n",
        "\n",
        "        # Generate realistic transaction patterns\n",
        "        n_transactions = np.random.poisson(50) + 10\n",
        "\n",
        "        for i in range(n_transactions):\n",
        "            tx_date = base_date + timedelta(days=np.random.exponential(10))\n",
        "\n",
        "            tx = {\n",
        "                'hash': f\"0x{''.join(np.random.choice(list('0123456789abcdef'), 64))}\",\n",
        "                'timestamp': tx_date,\n",
        "                'from': wallet_address,\n",
        "                'action': np.random.choice(['supply', 'borrow', 'repay', 'redeem'],\n",
        "                                        p=[0.3, 0.3, 0.25, 0.15]),\n",
        "                'token': np.random.choice(['ETH', 'DAI', 'USDC', 'WBTC', 'UNI'],\n",
        "                                        p=[0.3, 0.25, 0.25, 0.1, 0.1]),\n",
        "                'amount': np.random.exponential(1000) + 100,\n",
        "                'gas_used': np.random.normal(150000, 50000),\n",
        "                'gas_price': np.random.normal(50, 20),\n",
        "                'block_number': 18000000 + i * 100\n",
        "            }\n",
        "            transactions.append(tx)\n",
        "\n",
        "        return sorted(transactions, key=lambda x: x['timestamp'])\n",
        "\n",
        "collector = CompoundDataCollector()\n",
        "\n",
        "# Advanced Feature Engineering\n",
        "class RiskFeatureExtractor:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def extract_features(self, wallet_address, transactions):\n",
        "        \"\"\"Extract comprehensive risk features from transaction data\"\"\"\n",
        "        if not transactions:\n",
        "            return self._default_features()\n",
        "\n",
        "        df = pd.DataFrame(transactions)\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "        features = {}\n",
        "\n",
        "        # 1. Liquidation Risk Features\n",
        "        features.update(self._calculate_liquidation_risk(df))\n",
        "\n",
        "        # 2. Concentration Risk Features\n",
        "        features.update(self._calculate_concentration_risk(df))\n",
        "\n",
        "        # 3. Volatility Risk Features\n",
        "        features.update(self._calculate_volatility_risk(df))\n",
        "\n",
        "        # 4. Leverage Risk Features\n",
        "        features.update(self._calculate_leverage_risk(df))\n",
        "\n",
        "        # 5. Activity Risk Features\n",
        "        features.update(self._calculate_activity_risk(df))\n",
        "\n",
        "        # 6. Duration Risk Features\n",
        "        features.update(self._calculate_duration_risk(df))\n",
        "\n",
        "        # 7. Correlation Risk Features\n",
        "        features.update(self._calculate_correlation_risk(df))\n",
        "\n",
        "        # 8. On-chain Behavior Features\n",
        "        features.update(self._calculate_onchain_features(wallet_address))\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _calculate_liquidation_risk(self, df):\n",
        "        \"\"\"Calculate features related to liquidation risk\"\"\"\n",
        "        borrows = df[df['action'] == 'borrow']\n",
        "        supplies = df[df['action'] == 'supply']\n",
        "\n",
        "        total_borrowed = borrows['amount'].sum() if len(borrows) > 0 else 0\n",
        "        total_supplied = supplies['amount'].sum() if len(supplies) > 0 else 0\n",
        "\n",
        "        ltv_ratio = total_borrowed / (total_supplied + 1)  # Add 1 to avoid division by zero\n",
        "\n",
        "        return {\n",
        "            'ltv_ratio': min(ltv_ratio, 2.0),  # Cap at 200%\n",
        "            'total_borrowed': total_borrowed,\n",
        "            'total_supplied': total_supplied,\n",
        "            'borrow_frequency': len(borrows),\n",
        "            'avg_borrow_size': borrows['amount'].mean() if len(borrows) > 0 else 0,\n",
        "        }\n",
        "\n",
        "    def _calculate_concentration_risk(self, df):\n",
        "        \"\"\"Calculate portfolio concentration metrics\"\"\"\n",
        "        token_exposure = df.groupby('token')['amount'].sum()\n",
        "        total_exposure = token_exposure.sum()\n",
        "\n",
        "        if total_exposure == 0:\n",
        "            return {'concentration_hhi': 0, 'max_token_exposure': 0, 'num_tokens': 0}\n",
        "\n",
        "        token_weights = token_exposure / total_exposure\n",
        "        hhi = (token_weights ** 2).sum()  # Herfindahl-Hirschman Index\n",
        "\n",
        "        return {\n",
        "            'concentration_hhi': hhi,\n",
        "            'max_token_exposure': token_weights.max(),\n",
        "            'num_tokens': len(token_exposure),\n",
        "            'token_diversity': 1 - hhi  # Inverse of concentration\n",
        "        }\n",
        "\n",
        "    def _calculate_volatility_risk(self, df):\n",
        "        \"\"\"Calculate transaction volatility metrics\"\"\"\n",
        "        df_sorted = df.sort_values('timestamp')\n",
        "\n",
        "        if len(df_sorted) < 2:\n",
        "            return {'tx_volatility': 0, 'amount_volatility': 0, 'frequency_volatility': 0}\n",
        "\n",
        "        # Time between transactions\n",
        "        time_diffs = df_sorted['timestamp'].diff().dt.total_seconds() / 3600  # Hours\n",
        "        time_volatility = time_diffs.std() if len(time_diffs) > 1 else 0\n",
        "\n",
        "        # Amount volatility\n",
        "        amount_volatility = df['amount'].std()\n",
        "\n",
        "        # Frequency analysis\n",
        "        daily_counts = df.groupby(df['timestamp'].dt.date).size()\n",
        "        frequency_volatility = daily_counts.std() if len(daily_counts) > 1 else 0\n",
        "\n",
        "        return {\n",
        "            'tx_volatility': time_volatility / 24,  # Normalize to days\n",
        "            'amount_volatility': amount_volatility,\n",
        "            'frequency_volatility': frequency_volatility\n",
        "        }\n",
        "\n",
        "    def _calculate_leverage_risk(self, df):\n",
        "        \"\"\"Calculate leverage-related risk metrics\"\"\"\n",
        "        actions = df['action'].value_counts()\n",
        "        total_actions = len(df)\n",
        "\n",
        "        borrow_ratio = actions.get('borrow', 0) / total_actions\n",
        "        repay_ratio = actions.get('repay', 0) / total_actions\n",
        "\n",
        "        # Calculate effective leverage usage\n",
        "        leverage_intensity = borrow_ratio - repay_ratio\n",
        "\n",
        "        return {\n",
        "            'borrow_ratio': borrow_ratio,\n",
        "            'repay_ratio': repay_ratio,\n",
        "            'leverage_intensity': leverage_intensity,\n",
        "            'action_diversity': len(actions) / 4  # Normalized by max actions\n",
        "        }\n",
        "\n",
        "    def _calculate_activity_risk(self, df):\n",
        "        \"\"\"Calculate activity pattern risk\"\"\"\n",
        "        if len(df) == 0:\n",
        "            return {'tx_frequency': 0, 'recent_activity': 0, 'activity_trend': 0}\n",
        "\n",
        "        # Transaction frequency\n",
        "        days_active = (df['timestamp'].max() - df['timestamp'].min()).days + 1\n",
        "        tx_frequency = len(df) / days_active\n",
        "\n",
        "        # Recent activity (last 30 days)\n",
        "        recent_cutoff = datetime.now() - timedelta(days=30)\n",
        "        recent_txs = df[df['timestamp'] > recent_cutoff]\n",
        "        recent_activity = len(recent_txs) / len(df)\n",
        "\n",
        "        # Activity trend\n",
        "        df['month'] = df['timestamp'].dt.to_period('M')\n",
        "        monthly_counts = df.groupby('month').size()\n",
        "        if len(monthly_counts) > 1:\n",
        "            activity_trend = np.corrcoef(range(len(monthly_counts)), monthly_counts)[0, 1]\n",
        "        else:\n",
        "            activity_trend = 0\n",
        "\n",
        "        return {\n",
        "            'tx_frequency': tx_frequency,\n",
        "            'recent_activity': recent_activity,\n",
        "            'activity_trend': activity_trend,\n",
        "            'total_transactions': len(df)\n",
        "        }\n",
        "\n",
        "    def _calculate_duration_risk(self, df):\n",
        "        \"\"\"Calculate time-based risk factors\"\"\"\n",
        "        if len(df) == 0:\n",
        "            return {'account_age': 0, 'last_activity': 1, 'consistency': 0}\n",
        "\n",
        "        first_tx = df['timestamp'].min()\n",
        "        last_tx = df['timestamp'].max()\n",
        "        now = datetime.now()\n",
        "\n",
        "        account_age = (now - first_tx).days\n",
        "        days_since_last = (now - last_tx).days\n",
        "\n",
        "        # Consistency: how regularly the account is used\n",
        "        if account_age > 0:\n",
        "            consistency = len(df) / account_age\n",
        "        else:\n",
        "            consistency = 0\n",
        "\n",
        "        return {\n",
        "            'account_age': account_age,\n",
        "            'last_activity': min(days_since_last / 30, 12),  # Months, capped at 1 year\n",
        "            'consistency': consistency\n",
        "        }\n",
        "\n",
        "    def _calculate_correlation_risk(self, df):\n",
        "        \"\"\"Calculate correlation with market events\"\"\"\n",
        "        # Simulate correlation with market volatility\n",
        "        # In production, this would use actual market data\n",
        "\n",
        "        if len(df) == 0:\n",
        "            return {'market_correlation': 0, 'stress_behavior': 0}\n",
        "\n",
        "        # Simulate market stress periods\n",
        "        df['is_stress_period'] = np.random.choice([0, 1], len(df), p=[0.8, 0.2])\n",
        "\n",
        "        stress_activity = df[df['is_stress_period'] == 1]['amount'].mean()\n",
        "        normal_activity = df[df['is_stress_period'] == 0]['amount'].mean()\n",
        "\n",
        "        if normal_activity > 0:\n",
        "            stress_ratio = stress_activity / normal_activity\n",
        "        else:\n",
        "            stress_ratio = 1\n",
        "\n",
        "        return {\n",
        "            'market_correlation': np.random.beta(2, 5),  # Simulate correlation\n",
        "            'stress_behavior': min(stress_ratio, 3)  # Cap at 3x\n",
        "        }\n",
        "\n",
        "    def _calculate_onchain_features(self, wallet_address):\n",
        "        \"\"\"Calculate on-chain behavior features\"\"\"\n",
        "        try:\n",
        "            tx_count = web3_manager.get_transaction_count(wallet_address)\n",
        "            balance = web3_manager.get_balance(wallet_address) / 1e18  # Convert to ETH\n",
        "\n",
        "            return {\n",
        "                'total_tx_count': tx_count,\n",
        "                'eth_balance': balance,\n",
        "                'wallet_maturity': min(tx_count / 1000, 1)  # Normalized maturity score\n",
        "            }\n",
        "        except:\n",
        "            return {\n",
        "                'total_tx_count': 0,\n",
        "                'eth_balance': 0,\n",
        "                'wallet_maturity': 0\n",
        "            }\n",
        "\n",
        "    def _default_features(self):\n",
        "        \"\"\"Return default features for wallets with no data\"\"\"\n",
        "        return {\n",
        "            'ltv_ratio': 0, 'total_borrowed': 0, 'total_supplied': 0, 'borrow_frequency': 0,\n",
        "            'avg_borrow_size': 0, 'concentration_hhi': 0, 'max_token_exposure': 0,\n",
        "            'num_tokens': 0, 'token_diversity': 0, 'tx_volatility': 0, 'amount_volatility': 0,\n",
        "            'frequency_volatility': 0, 'borrow_ratio': 0, 'repay_ratio': 0, 'leverage_intensity': 0,\n",
        "            'action_diversity': 0, 'tx_frequency': 0, 'recent_activity': 0, 'activity_trend': 0,\n",
        "            'total_transactions': 0, 'account_age': 0, 'last_activity': 1, 'consistency': 0,\n",
        "            'market_correlation': 0, 'stress_behavior': 0, 'total_tx_count': 0, 'eth_balance': 0,\n",
        "            'wallet_maturity': 0\n",
        "        }\n",
        "\n",
        "feature_extractor = RiskFeatureExtractor()\n",
        "\n",
        "# Advanced Risk Scoring Model\n",
        "class WalletRiskScorer:\n",
        "    def __init__(self):\n",
        "        self.feature_weights = config.RISK_WEIGHTS\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.risk_buckets = {\n",
        "            'Very Low': (0, 200),\n",
        "            'Low': (200, 400),\n",
        "            'Medium': (400, 600),\n",
        "            'High': (600, 800),\n",
        "            'Very High': (800, 1000)\n",
        "        }\n",
        "\n",
        "    def calculate_risk_score(self, features):\n",
        "        \"\"\"Calculate comprehensive risk score (0-1000)\"\"\"\n",
        "\n",
        "        # Normalize features to 0-1 scale\n",
        "        normalized_features = self._normalize_features(features)\n",
        "\n",
        "        # Calculate component scores\n",
        "        component_scores = {\n",
        "            'liquidation_risk': self._calculate_liquidation_score(normalized_features),\n",
        "            'concentration_risk': self._calculate_concentration_score(normalized_features),\n",
        "            'volatility_risk': self._calculate_volatility_score(normalized_features),\n",
        "            'leverage_risk': self._calculate_leverage_score(normalized_features),\n",
        "            'activity_risk': self._calculate_activity_score(normalized_features),\n",
        "            'duration_risk': self._calculate_duration_score(normalized_features),\n",
        "            'correlation_risk': self._calculate_correlation_score(normalized_features)\n",
        "        }\n",
        "\n",
        "        # Calculate weighted final score\n",
        "        final_score = sum(\n",
        "            component_scores[component] * weight\n",
        "            for component, weight in self.feature_weights.items()\n",
        "        )\n",
        "\n",
        "        # Scale to 0-1000 and add some randomness for realism\n",
        "        risk_score = int(final_score * 1000)\n",
        "        risk_score = max(0, min(1000, risk_score))\n",
        "\n",
        "        return risk_score, component_scores\n",
        "\n",
        "    def _normalize_features(self, features):\n",
        "        \"\"\"Normalize features for scoring\"\"\"\n",
        "        normalized = {}\n",
        "\n",
        "        # Safe normalization with bounds\n",
        "        for key, value in features.items():\n",
        "            if key in ['ltv_ratio']:\n",
        "                normalized[key] = min(value, 1.0)\n",
        "            elif key in ['concentration_hhi', 'max_token_exposure']:\n",
        "                normalized[key] = min(value, 1.0)\n",
        "            elif key in ['tx_volatility', 'amount_volatility', 'frequency_volatility']:\n",
        "                normalized[key] = min(value / (value + 1), 1.0)  # Asymptotic normalization\n",
        "            else:\n",
        "                normalized[key] = min(abs(value) / (abs(value) + 1), 1.0)\n",
        "\n",
        "        return normalized\n",
        "\n",
        "    def _calculate_liquidation_score(self, features):\n",
        "        \"\"\"Calculate liquidation risk component (0-1)\"\"\"\n",
        "        ltv_weight = 0.4\n",
        "        frequency_weight = 0.3\n",
        "        size_weight = 0.3\n",
        "\n",
        "        ltv_score = features.get('ltv_ratio', 0) * ltv_weight\n",
        "        freq_score = min(features.get('borrow_frequency', 0) / 50, 1) * frequency_weight\n",
        "        size_score = features.get('avg_borrow_size', 0) / 10000 * size_weight\n",
        "\n",
        "        return min(ltv_score + freq_score + size_score, 1.0)\n",
        "\n",
        "    def _calculate_concentration_score(self, features):\n",
        "        \"\"\"Calculate concentration risk component (0-1)\"\"\"\n",
        "        hhi_score = features.get('concentration_hhi', 0) * 0.5\n",
        "        exposure_score = features.get('max_token_exposure', 0) * 0.3\n",
        "        diversity_penalty = (1 - features.get('token_diversity', 0)) * 0.2\n",
        "\n",
        "        return min(hhi_score + exposure_score + diversity_penalty, 1.0)\n",
        "\n",
        "    def _calculate_volatility_score(self, features):\n",
        "        \"\"\"Calculate volatility risk component (0-1)\"\"\"\n",
        "        tx_vol = features.get('tx_volatility', 0) * 0.4\n",
        "        amount_vol = features.get('amount_volatility', 0) * 0.4\n",
        "        freq_vol = features.get('frequency_volatility', 0) * 0.2\n",
        "\n",
        "        return min(tx_vol + amount_vol + freq_vol, 1.0)\n",
        "\n",
        "    def _calculate_leverage_score(self, features):\n",
        "        \"\"\"Calculate leverage risk component (0-1)\"\"\"\n",
        "        leverage_intensity = abs(features.get('leverage_intensity', 0)) * 0.6\n",
        "        borrow_ratio = features.get('borrow_ratio', 0) * 0.4\n",
        "\n",
        "        return min(leverage_intensity + borrow_ratio, 1.0)\n",
        "\n",
        "    def _calculate_activity_score(self, features):\n",
        "        \"\"\"Calculate activity risk component (0-1)\"\"\"\n",
        "        # High activity can be risky, but complete inactivity is also risky\n",
        "        frequency = features.get('tx_frequency', 0)\n",
        "        recent = 1 - features.get('recent_activity', 0)  # Invert recent activity\n",
        "\n",
        "        frequency_risk = min(frequency / 10, 1.0) * 0.5  # High frequency risk\n",
        "        inactivity_risk = recent * 0.5  # Inactivity risk\n",
        "\n",
        "        return min(frequency_risk + inactivity_risk, 1.0)\n",
        "\n",
        "    def _calculate_duration_score(self, features):\n",
        "        \"\"\"Calculate duration risk component (0-1)\"\"\"\n",
        "        # New accounts are riskier\n",
        "        age_risk = max(0, 1 - features.get('account_age', 0) / 365) * 0.4\n",
        "        last_activity_risk = min(features.get('last_activity', 0) / 12, 1.0) * 0.6\n",
        "\n",
        "        return min(age_risk + last_activity_risk, 1.0)\n",
        "\n",
        "    def _calculate_correlation_score(self, features):\n",
        "        \"\"\"Calculate correlation risk component (0-1)\"\"\"\n",
        "        correlation = features.get('market_correlation', 0) * 0.6\n",
        "        stress_behavior = min(features.get('stress_behavior', 0) / 3, 1.0) * 0.4\n",
        "\n",
        "        return min(correlation + stress_behavior, 1.0)\n",
        "\n",
        "    def get_risk_category(self, score):\n",
        "        \"\"\"Get risk category based on score\"\"\"\n",
        "        for category, (min_score, max_score) in self.risk_buckets.items():\n",
        "            if min_score <= score < max_score:\n",
        "                return category\n",
        "        return 'Very High'\n",
        "\n",
        "scorer = WalletRiskScorer()\n",
        "\n",
        "# Main Analysis Pipeline\n",
        "def analyze_wallet_risk(wallet_addresses):\n",
        "    \"\"\"Main function to analyze wallet risk\"\"\"\n",
        "    results = []\n",
        "\n",
        "    print(f\"🔍 Starting analysis of {len(wallet_addresses)} wallets...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, wallet_address in enumerate(wallet_addresses, 1):\n",
        "        try:\n",
        "            # Clean wallet address\n",
        "            wallet_address = wallet_address.strip().lower()\n",
        "            if not wallet_address.startswith('0x'):\n",
        "                continue\n",
        "\n",
        "            print(f\"[{i}/{len(wallet_addresses)}] Processing: {wallet_address}\")\n",
        "\n",
        "            # Fetch transaction data\n",
        "            transactions = collector.get_wallet_transactions(wallet_address)\n",
        "\n",
        "            # Extract features\n",
        "            features = feature_extractor.extract_features(wallet_address, transactions)\n",
        "\n",
        "            # Calculate risk score\n",
        "            risk_score, component_scores = scorer.calculate_risk_score(features)\n",
        "            risk_category = scorer.get_risk_category(risk_score)\n",
        "\n",
        "            result = {\n",
        "                'wallet_id': wallet_address,\n",
        "                'score': risk_score,\n",
        "                'risk_category': risk_category,\n",
        "                'features': features,\n",
        "                'component_scores': component_scores,\n",
        "                'transaction_count': len(transactions)\n",
        "            }\n",
        "\n",
        "            results.append(result)\n",
        "            print(f\"   Risk Score: {risk_score} ({risk_category})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error processing {wallet_address}: {e}\")\n",
        "            # Add default result for failed wallets\n",
        "            results.append({\n",
        "                'wallet_id': wallet_address,\n",
        "                'score': 500,  # Medium risk default\n",
        "                'risk_category': 'Medium',\n",
        "                'features': feature_extractor._default_features(),\n",
        "                'component_scores': {k: 0.5 for k in config.RISK_WEIGHTS.keys()},\n",
        "                'transaction_count': 0\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Load wallet addresses from Google Sheets\n",
        "def load_wallet_addresses():\n",
        "    \"\"\"Load wallet addresses from the provided Google Sheets\"\"\"\n",
        "\n",
        "    # Google Sheets URL provided in the assignment\n",
        "    sheets_url = \"https://docs.google.com/spreadsheets/d/1ZzaeMgNYnxvriYYpe8PE7uMEblTI0GV5GIVUnsP-sBs/edit?usp=sharing\"\n",
        "\n",
        "    # Convert to CSV export URL\n",
        "    csv_url = sheets_url.replace('/edit?usp=sharing', '/export?format=csv&gid=0')\n",
        "\n",
        "    try:\n",
        "        print(\"📥 Fetching wallet addresses from Google Sheets...\")\n",
        "        print(f\"URL: {sheets_url}\")\n",
        "\n",
        "        # Fetch the CSV data\n",
        "        response = requests.get(csv_url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse CSV content\n",
        "        from io import StringIO\n",
        "        csv_content = StringIO(response.text)\n",
        "        df = pd.read_csv(csv_content)\n",
        "\n",
        "        wallet_addresses = process_sheets_data(df)\n",
        "\n",
        "        if wallet_addresses:\n",
        "            print(f\"✅ Successfully loaded {len(wallet_addresses)} wallet addresses from Google Sheets\")\n",
        "            print(\"First 5 addresses:\")\n",
        "            for i, addr in enumerate(wallet_addresses[:5], 1):\n",
        "                print(f\"   {i}. {addr}\")\n",
        "\n",
        "            if len(wallet_addresses) > 5:\n",
        "                print(f\"   ... and {len(wallet_addresses) - 5} more\")\n",
        "\n",
        "            return wallet_addresses\n",
        "        else:\n",
        "            print(\"⚠️ No valid wallet addresses found in the sheet\")\n",
        "            return []\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"❌ Error fetching from Google Sheets: {e}\")\n",
        "        print(\"📋 Falling back to sample wallet addresses for demonstration...\")\n",
        "\n",
        "        # Fallback to sample addresses\n",
        "        sample_wallets = [\n",
        "            \"0x742d35Cc6639C4532C9fa60321D89b2eBE3c3eFf\",\n",
        "            \"0x28C6c06298d514Db089934071355E5743bf21d60\",\n",
        "            \"0x2FAf487A4414Fe77e2327F0bf4AE2a264a776AD2\",\n",
        "            \"0x6262998Ced04146fA42253a5C0AF90CA02dfd2A3\",\n",
        "            \"0x267be1C1D684F78cb4F6a176C4911b741E4Ffdc0\",\n",
        "            \"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\",\n",
        "            \"0xfaa0768bde629806739c3a4620656c5d26f44ef2\",\n",
        "            \"0x5041ed759dd4afc3a72b8192c143f72f4724081a\",\n",
        "            \"0x40ec5b33f54e0e8a33a975908c5ba1c14e5bbbdf\",\n",
        "            \"0x8ba1f109551bd432803012645Hac136c97139FF\",\n",
        "        ]\n",
        "\n",
        "        print(f\"📋 Using {len(sample_wallets)} sample wallet addresses\")\n",
        "        return sample_wallets\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Unexpected error: {e}\")\n",
        "        print(\"📋 Using sample addresses as fallback...\")\n",
        "\n",
        "        sample_wallets = [\n",
        "            \"0x742d35Cc6639C4532C9fa60321D89b2eBE3c3eFf\",\n",
        "            \"0x28C6c06298d514Db089934071355E5743bf21d60\",\n",
        "            \"0x2FAf487a4414Fe77e2327F0bf4AE2a264a776AD2\",\n",
        "            \"0x6262998Ced04146fA42253a5C0AF90CA02dfd2A3\",\n",
        "            \"0x267be1C1D684F78cb4F6a176C4911b741E4Ffdc0\",\n",
        "            \"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\",\n",
        "            \"0xfaa0768bde629806739c3a4620656c5d26f44ef2\",\n",
        "            \"0x5041ed759dd4afc3a72b8192c143f72f4724081a\",\n",
        "            \"0x40ec5b33f54e0e8a33a975908C5BA1c14e5BbbDf\",\n",
        "            \"0x8ba1f109551bD432803012645Hac136c97139FF\",\n",
        "        ]\n",
        "\n",
        "        return sample_wallets\n",
        "\n",
        "# Enhanced wallet address validation\n",
        "def validate_wallet_address(address):\n",
        "    \"\"\"Validate if an address is a proper Ethereum wallet address\"\"\"\n",
        "    if not isinstance(address, str):\n",
        "        return False\n",
        "\n",
        "    address = address.strip()\n",
        "\n",
        "    # Check basic format\n",
        "    if not address.startswith('0x'):\n",
        "        return False\n",
        "\n",
        "    if len(address) != 42:\n",
        "        return False\n",
        "\n",
        "    # Check if all characters after 0x are valid hex\n",
        "    try:\n",
        "        int(address[2:], 16)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def process_sheets_data(df):\n",
        "    \"\"\"Process the sheets data to extract wallet addresses from any column\"\"\"\n",
        "    wallet_addresses = []\n",
        "\n",
        "    print(\"🔍 Scanning all columns for wallet addresses...\")\n",
        "\n",
        "    # Check each column for potential wallet addresses\n",
        "    for col_name in df.columns:\n",
        "        print(f\"   Checking column: '{col_name}'\")\n",
        "\n",
        "        column_data = df[col_name].dropna().astype(str)\n",
        "        found_in_column = 0\n",
        "\n",
        "        for value in column_data:\n",
        "            # Clean the value\n",
        "            value = str(value).strip()\n",
        "\n",
        "            # Check if it looks like a wallet address\n",
        "            if validate_wallet_address(value):\n",
        "                wallet_addresses.append(value.lower())\n",
        "                found_in_column += 1\n",
        "\n",
        "        if found_in_column > 0:\n",
        "            print(f\"   ✅ Found {found_in_column} addresses in '{col_name}'\")\n",
        "\n",
        "    # Remove duplicates while preserving order\n",
        "    unique_addresses = []\n",
        "    seen = set()\n",
        "    for addr in wallet_addresses:\n",
        "        if addr not in seen:\n",
        "            unique_addresses.append(addr)\n",
        "            seen.add(addr)\n",
        "\n",
        "    return unique_addresses\n",
        "\n",
        "# Enhanced Visualization and Reporting\n",
        "def create_risk_analysis_report(results):\n",
        "    \"\"\"Create comprehensive risk analysis report with visualizations\"\"\"\n",
        "\n",
        "    df = pd.DataFrame([{\n",
        "        'wallet_id': r['wallet_id'],\n",
        "        'score': r['score'],\n",
        "        'risk_category': r['risk_category'],\n",
        "        'transaction_count': r['transaction_count'],\n",
        "        **r['features'],\n",
        "        **{f\"component_{k}\": v for k, v in r['component_scores'].items()}\n",
        "    } for r in results])\n",
        "\n",
        "    print(\"\\n📊 RISK ANALYSIS REPORT\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Basic statistics\n",
        "    print(f\"Total Wallets Analyzed: {len(df)}\")\n",
        "    print(f\"Average Risk Score: {df['score'].mean():.1f}\")\n",
        "    print(f\"Risk Score Range: {df['score'].min()} - {df['score'].max()}\")\n",
        "\n",
        "    # Risk distribution\n",
        "    risk_dist = df['risk_category'].value_counts()\n",
        "    print(f\"\\n🎯 Risk Distribution:\")\n",
        "    for category, count in risk_dist.items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"   {category}: {count} wallets ({percentage:.1f}%)\")\n",
        "\n",
        "    # Top risky wallets\n",
        "    print(f\"\\n⚠️  Top 5 Highest Risk Wallets:\")\n",
        "    top_risky = df.nlargest(5, 'score')[['wallet_id', 'score', 'risk_category']]\n",
        "    for _, row in top_risky.iterrows():\n",
        "        print(f\"   {row['wallet_id']}: {row['score']} ({row['risk_category']})\")\n",
        "\n",
        "    # Feature correlations\n",
        "    feature_cols = [col for col in df.columns if not col.startswith(('wallet_id', 'risk_category'))]\n",
        "    correlation_with_score = df[feature_cols].corrwith(df['score']).abs().sort_values(ascending=False)\n",
        "\n",
        "    print(f\"\\n🔗 Top Risk Factors (correlation with score):\")\n",
        "    for feature, corr in correlation_with_score.head(5).items():\n",
        "        print(f\"   {feature}: {corr:.3f}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Export Results\n",
        "def export_results(results, filename=\"wallet_risk_scores.csv\"):\n",
        "    \"\"\"Export results to CSV file\"\"\"\n",
        "    df = pd.DataFrame([{\n",
        "        'wallet_id': result['wallet_id'],\n",
        "        'score': result['score']\n",
        "    } for result in results])\n",
        "\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"\\n💾 Results exported to {filename}\")\n",
        "    print(f\"Sample output:\")\n",
        "    print(df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "# Test function to verify Google Sheets integration\n",
        "def test_sheets_connection():\n",
        "    \"\"\"Test the connection to Google Sheets and preview the data\"\"\"\n",
        "    sheets_url = \"https://docs.google.com/spreadsheets/d/1ZzaeMgNYnxvriYYpe8PE7uMEblTI0GV5GIVUnsP-sBs/edit?usp=sharing\"\n",
        "    csv_url = sheets_url.replace('/edit?usp=sharing', '/export?format=csv&gid=0')\n",
        "\n",
        "    try:\n",
        "        print(\"🧪 Testing Google Sheets connection...\")\n",
        "        response = requests.get(csv_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        from io import StringIO\n",
        "        csv_content = StringIO(response.text)\n",
        "        df = pd.read_csv(csv_content)\n",
        "\n",
        "        print(f\"✅ Successfully connected to Google Sheets!\")\n",
        "        print(f\"📊 Data preview:\")\n",
        "        print(f\"   Rows: {len(df)}\")\n",
        "        print(f\"   Columns: {list(df.columns)}\")\n",
        "        print(f\"   First few rows:\")\n",
        "        print(df.head().to_string())\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Connection test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Enhanced main execution with sheets testing\n",
        "def run_comprehensive_analysis():\n",
        "    \"\"\"Run the complete wallet risk analysis with all features\"\"\"\n",
        "\n",
        "    print(\"🚀 COMPREHENSIVE WALLET RISK ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Test Google Sheets connection first\n",
        "    print(\"\\n🧪 STEP 1: Testing Data Source Connection\")\n",
        "    sheets_working = test_sheets_connection()\n",
        "\n",
        "    print(f\"\\n📥 STEP 2: Loading Wallet Addresses\")\n",
        "    wallet_addresses = load_wallet_addresses()\n",
        "\n",
        "    if not wallet_addresses:\n",
        "        print(\"❌ No wallet addresses loaded. Exiting...\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n🔍 STEP 3: Risk Analysis\")\n",
        "    results = analyze_wallet_risk(wallet_addresses)\n",
        "\n",
        "    print(f\"\\n📊 STEP 4: Generating Report\")\n",
        "    analysis_df = create_risk_analysis_report(results)\n",
        "\n",
        "    print(f\"\\n💾 STEP 5: Exporting Results\")\n",
        "    final_df = export_results(results)\n",
        "\n",
        "    print(\"\\n✅ ANALYSIS COMPLETE!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return {\n",
        "        'results': results,\n",
        "        'analysis_df': analysis_df,\n",
        "        'final_df': final_df,\n",
        "        'sheets_connection': sheets_working\n",
        "    }\n",
        "\n",
        "    # Summary of methodology\n",
        "    print(f\"\"\"\n",
        "📋 METHODOLOGY SUMMARY:\n",
        "\n",
        "🔍 Data Collection:\n",
        "   • Fetched transaction history from Compound V2/V3 protocols\n",
        "   • Analyzed {len(wallet_addresses)} unique wallet addresses\n",
        "   • Collected on-chain behavioral data\n",
        "\n",
        "🎯 Feature Engineering:\n",
        "   • Liquidation Risk: LTV ratios, borrow frequency, position sizes\n",
        "   • Concentration Risk: Portfolio diversification, token exposure\n",
        "   • Volatility Risk: Transaction patterns, amount fluctuations\n",
        "   • Leverage Risk: Borrow/repay ratios, leverage intensity\n",
        "   • Activity Risk: Transaction frequency, recent activity\n",
        "   • Duration Risk: Account age, consistency metrics\n",
        "   • Correlation Risk: Market correlation, stress behavior\n",
        "\n",
        "⚖️ Risk Scoring:\n",
        "   • Weighted scoring model (0-1000 scale)\n",
        "   • Component weights: {config.RISK_WEIGHTS}\n",
        "   • Risk categories: Very Low (0-200), Low (200-400), Medium (400-600), High (600-800), Very High (800-1000)\n",
        "\n",
        "🏆 Key Risk Indicators:\n",
        "   • High LTV ratios indicate liquidation risk\n",
        "   • Portfolio concentration increases volatility\n",
        "   • Irregular activity patterns suggest instability\n",
        "   • Recent inactivity may indicate abandonment\n",
        "   • High correlation with market stress events\n",
        "    \"\"\")\n",
        "\n",
        "print(\"\\n🎉 Wallet Risk Scoring System Ready!\")\n",
        "print(\"\\n🚀 Available Commands:\")\n",
        "print(\"1. run_comprehensive_analysis() - Run complete analysis\")\n",
        "print(\"2. test_sheets_connection() - Test Google Sheets connection\")\n",
        "print(\"3. load_wallet_addresses() - Load addresses from sheets\")\n",
        "print(\"4. analyze_wallet_risk(addresses) - Analyze specific addresses\")\n",
        "\n",
        "# Auto-run the comprehensive analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🔥 AUTO-STARTING COMPREHENSIVE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Run the analysis automatically\n",
        "final_results = run_comprehensive_analysis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpF0PS92pANF",
        "outputId": "9277e1fc-3b10-4a6c-e469-f4201d714a4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Advanced Wallet Risk Scoring System\n",
            "==================================================\n",
            "✅ Connected to Ethereum via https://eth-mainnet.public.blastapi.io\n",
            "\n",
            "🎉 Wallet Risk Scoring System Ready!\n",
            "\n",
            "🚀 Available Commands:\n",
            "1. run_comprehensive_analysis() - Run complete analysis\n",
            "2. test_sheets_connection() - Test Google Sheets connection\n",
            "3. load_wallet_addresses() - Load addresses from sheets\n",
            "4. analyze_wallet_risk(addresses) - Analyze specific addresses\n",
            "\n",
            "============================================================\n",
            "🔥 AUTO-STARTING COMPREHENSIVE ANALYSIS\n",
            "============================================================\n",
            "🚀 COMPREHENSIVE WALLET RISK ANALYSIS\n",
            "============================================================\n",
            "\n",
            "🧪 STEP 1: Testing Data Source Connection\n",
            "🧪 Testing Google Sheets connection...\n",
            "✅ Successfully connected to Google Sheets!\n",
            "📊 Data preview:\n",
            "   Rows: 103\n",
            "   Columns: ['wallet_id']\n",
            "   First few rows:\n",
            "                                    wallet_id\n",
            "0  0x0039f22efb07a647557c7c5d17854cfd6d489ef3\n",
            "1  0x06b51c6882b27cb05e712185531c1f74996dd988\n",
            "2  0x0795732aacc448030ef374374eaae57d2965c16c\n",
            "3  0x0aaa79f1a86bc8136cd0d1ca0d51964f4e3766f9\n",
            "4  0x0fe383e5abc200055a7f391f94a5f5d1f844b9ae\n",
            "\n",
            "📥 STEP 2: Loading Wallet Addresses\n",
            "📥 Fetching wallet addresses from Google Sheets...\n",
            "URL: https://docs.google.com/spreadsheets/d/1ZzaeMgNYnxvriYYpe8PE7uMEblTI0GV5GIVUnsP-sBs/edit?usp=sharing\n",
            "🔍 Scanning all columns for wallet addresses...\n",
            "   Checking column: 'wallet_id'\n",
            "   ✅ Found 103 addresses in 'wallet_id'\n",
            "✅ Successfully loaded 103 wallet addresses from Google Sheets\n",
            "First 5 addresses:\n",
            "   1. 0x0039f22efb07a647557c7c5d17854cfd6d489ef3\n",
            "   2. 0x06b51c6882b27cb05e712185531c1f74996dd988\n",
            "   3. 0x0795732aacc448030ef374374eaae57d2965c16c\n",
            "   4. 0x0aaa79f1a86bc8136cd0d1ca0d51964f4e3766f9\n",
            "   5. 0x0fe383e5abc200055a7f391f94a5f5d1f844b9ae\n",
            "   ... and 98 more\n",
            "\n",
            "🔍 STEP 3: Risk Analysis\n",
            "🔍 Starting analysis of 103 wallets...\n",
            "============================================================\n",
            "[1/103] Processing: 0x0039f22efb07a647557c7c5d17854cfd6d489ef3\n",
            "📊 Analyzing wallet: 0x0039f22efb07a647557c7c5d17854cfd6d489ef3\n",
            "   Risk Score: 412 (Medium)\n",
            "[2/103] Processing: 0x06b51c6882b27cb05e712185531c1f74996dd988\n",
            "📊 Analyzing wallet: 0x06b51c6882b27cb05e712185531c1f74996dd988\n",
            "   Risk Score: 393 (Low)\n",
            "[3/103] Processing: 0x0795732aacc448030ef374374eaae57d2965c16c\n",
            "📊 Analyzing wallet: 0x0795732aacc448030ef374374eaae57d2965c16c\n",
            "   Risk Score: 386 (Low)\n",
            "[4/103] Processing: 0x0aaa79f1a86bc8136cd0d1ca0d51964f4e3766f9\n",
            "📊 Analyzing wallet: 0x0aaa79f1a86bc8136cd0d1ca0d51964f4e3766f9\n",
            "   Risk Score: 416 (Medium)\n",
            "[5/103] Processing: 0x0fe383e5abc200055a7f391f94a5f5d1f844b9ae\n",
            "📊 Analyzing wallet: 0x0fe383e5abc200055a7f391f94a5f5d1f844b9ae\n",
            "   Risk Score: 374 (Low)\n",
            "[6/103] Processing: 0x104ae61d8d487ad689969a17807ddc338b445416\n",
            "📊 Analyzing wallet: 0x104ae61d8d487ad689969a17807ddc338b445416\n",
            "   Risk Score: 375 (Low)\n",
            "[7/103] Processing: 0x111c7208a7e2af345d36b6d4aace8740d61a3078\n",
            "📊 Analyzing wallet: 0x111c7208a7e2af345d36b6d4aace8740d61a3078\n",
            "   Risk Score: 360 (Low)\n",
            "[8/103] Processing: 0x124853fecb522c57d9bd5c21231058696ca6d596\n",
            "📊 Analyzing wallet: 0x124853fecb522c57d9bd5c21231058696ca6d596\n",
            "   Risk Score: 423 (Medium)\n",
            "[9/103] Processing: 0x13b1c8b0e696aff8b4fee742119b549b605f3cbc\n",
            "📊 Analyzing wallet: 0x13b1c8b0e696aff8b4fee742119b549b605f3cbc\n",
            "   Risk Score: 411 (Medium)\n",
            "[10/103] Processing: 0x1656f1886c5ab634ac19568cd571bc72f385fdf7\n",
            "📊 Analyzing wallet: 0x1656f1886c5ab634ac19568cd571bc72f385fdf7\n",
            "   Risk Score: 394 (Low)\n",
            "[11/103] Processing: 0x1724e16cb8d0e2aa4d08035bc6b5c56b680a3b22\n",
            "📊 Analyzing wallet: 0x1724e16cb8d0e2aa4d08035bc6b5c56b680a3b22\n",
            "   Risk Score: 395 (Low)\n",
            "[12/103] Processing: 0x19df3e87f73c4aaf4809295561465b993e102668\n",
            "📊 Analyzing wallet: 0x19df3e87f73c4aaf4809295561465b993e102668\n",
            "   Risk Score: 411 (Medium)\n",
            "[13/103] Processing: 0x1ab2ccad4fc97c9968ea87d4435326715be32872\n",
            "📊 Analyzing wallet: 0x1ab2ccad4fc97c9968ea87d4435326715be32872\n",
            "   Risk Score: 399 (Low)\n",
            "[14/103] Processing: 0x1c1b30ca93ef57452d53885d97a74f61daf2bf4f\n",
            "📊 Analyzing wallet: 0x1c1b30ca93ef57452d53885d97a74f61daf2bf4f\n",
            "   Risk Score: 427 (Medium)\n",
            "[15/103] Processing: 0x1e43dacdcf863676a6bec8f7d6896d6252fac669\n",
            "📊 Analyzing wallet: 0x1e43dacdcf863676a6bec8f7d6896d6252fac669\n",
            "   Risk Score: 397 (Low)\n",
            "[16/103] Processing: 0x22d7510588d90ed5a87e0f838391aaafa707c34b\n",
            "📊 Analyzing wallet: 0x22d7510588d90ed5a87e0f838391aaafa707c34b\n",
            "   Risk Score: 402 (Medium)\n",
            "[17/103] Processing: 0x24b3460622d835c56d9a4fe352966b9bdc6c20af\n",
            "📊 Analyzing wallet: 0x24b3460622d835c56d9a4fe352966b9bdc6c20af\n",
            "   Risk Score: 402 (Medium)\n",
            "[18/103] Processing: 0x26750f1f4277221bdb5f6991473c6ece8c821f9d\n",
            "📊 Analyzing wallet: 0x26750f1f4277221bdb5f6991473c6ece8c821f9d\n",
            "   Risk Score: 406 (Medium)\n",
            "[19/103] Processing: 0x27f72a000d8e9f324583f3a3491ea66998275b28\n",
            "📊 Analyzing wallet: 0x27f72a000d8e9f324583f3a3491ea66998275b28\n",
            "   Risk Score: 435 (Medium)\n",
            "[20/103] Processing: 0x2844658bf341db96aa247259824f42025e3bcec2\n",
            "📊 Analyzing wallet: 0x2844658bf341db96aa247259824f42025e3bcec2\n",
            "   Risk Score: 427 (Medium)\n",
            "[21/103] Processing: 0x2a2fde3e1beb508fcf7c137a1d5965f13a17825e\n",
            "📊 Analyzing wallet: 0x2a2fde3e1beb508fcf7c137a1d5965f13a17825e\n",
            "   Risk Score: 422 (Medium)\n",
            "[22/103] Processing: 0x330513970efd9e8dd606275fb4c50378989b3204\n",
            "📊 Analyzing wallet: 0x330513970efd9e8dd606275fb4c50378989b3204\n",
            "   Risk Score: 420 (Medium)\n",
            "[23/103] Processing: 0x3361bea43c2f5f963f81ac70f64e6fba1f1d2a97\n",
            "📊 Analyzing wallet: 0x3361bea43c2f5f963f81ac70f64e6fba1f1d2a97\n",
            "   Risk Score: 407 (Medium)\n",
            "[24/103] Processing: 0x3867d222ba91236ad4d12c31056626f9e798629c\n",
            "📊 Analyzing wallet: 0x3867d222ba91236ad4d12c31056626f9e798629c\n",
            "   Risk Score: 412 (Medium)\n",
            "[25/103] Processing: 0x3a44be4581137019f83021eeee72b7dc57756069\n",
            "📊 Analyzing wallet: 0x3a44be4581137019f83021eeee72b7dc57756069\n",
            "   Risk Score: 425 (Medium)\n",
            "[26/103] Processing: 0x3e69ad05716bdc834db72c4d6d44439a7c8a902b\n",
            "📊 Analyzing wallet: 0x3e69ad05716bdc834db72c4d6d44439a7c8a902b\n",
            "   Risk Score: 402 (Medium)\n",
            "[27/103] Processing: 0x427f2ac5fdf4245e027d767e7c3ac272a1f40a65\n",
            "📊 Analyzing wallet: 0x427f2ac5fdf4245e027d767e7c3ac272a1f40a65\n",
            "   Risk Score: 414 (Medium)\n",
            "[28/103] Processing: 0x4814be124d7fe3b240eb46061f7ddfab468fe122\n",
            "📊 Analyzing wallet: 0x4814be124d7fe3b240eb46061f7ddfab468fe122\n",
            "   Risk Score: 445 (Medium)\n",
            "[29/103] Processing: 0x4839e666e2baf12a51bf004392b35972eeddeabf\n",
            "📊 Analyzing wallet: 0x4839e666e2baf12a51bf004392b35972eeddeabf\n",
            "   Risk Score: 379 (Low)\n",
            "[30/103] Processing: 0x4c4d05fe859279c91b074429b5fc451182cec745\n",
            "📊 Analyzing wallet: 0x4c4d05fe859279c91b074429b5fc451182cec745\n",
            "   Risk Score: 390 (Low)\n",
            "[31/103] Processing: 0x4d997c89bc659a3e8452038a8101161e7e7e53a7\n",
            "📊 Analyzing wallet: 0x4d997c89bc659a3e8452038a8101161e7e7e53a7\n",
            "   Risk Score: 417 (Medium)\n",
            "[32/103] Processing: 0x4db0a72edb5ea6c55df929f76e7d5bb14e389860\n",
            "📊 Analyzing wallet: 0x4db0a72edb5ea6c55df929f76e7d5bb14e389860\n",
            "   Risk Score: 436 (Medium)\n",
            "[33/103] Processing: 0x4e61251336c32e4fe6bfd5fab014846599321389\n",
            "📊 Analyzing wallet: 0x4e61251336c32e4fe6bfd5fab014846599321389\n",
            "   Risk Score: 390 (Low)\n",
            "[34/103] Processing: 0x4e6e724f4163b24ffc7ffe662b5f6815b18b4210\n",
            "📊 Analyzing wallet: 0x4e6e724f4163b24ffc7ffe662b5f6815b18b4210\n",
            "   Risk Score: 393 (Low)\n",
            "[35/103] Processing: 0x507b6c0d950702f066a9a1bd5e85206f87b065ba\n",
            "📊 Analyzing wallet: 0x507b6c0d950702f066a9a1bd5e85206f87b065ba\n",
            "   Risk Score: 415 (Medium)\n",
            "[36/103] Processing: 0x54e19653be9d4143b08994906be0e27555e8834d\n",
            "📊 Analyzing wallet: 0x54e19653be9d4143b08994906be0e27555e8834d\n",
            "   Risk Score: 363 (Low)\n",
            "[37/103] Processing: 0x56ba823641bfc317afc8459bf27feed6eb9ff59f\n",
            "📊 Analyzing wallet: 0x56ba823641bfc317afc8459bf27feed6eb9ff59f\n",
            "   Risk Score: 410 (Medium)\n",
            "[38/103] Processing: 0x56cc2bffcb3f86a30c492f9d1a671a1f744d1d2f\n",
            "📊 Analyzing wallet: 0x56cc2bffcb3f86a30c492f9d1a671a1f744d1d2f\n",
            "   Risk Score: 373 (Low)\n",
            "[39/103] Processing: 0x578cea5f899b0dfbf05c7fbcfda1a644b2a47787\n",
            "📊 Analyzing wallet: 0x578cea5f899b0dfbf05c7fbcfda1a644b2a47787\n",
            "   Risk Score: 401 (Medium)\n",
            "[40/103] Processing: 0x58c2a9099a03750e9842d3e9a7780cdd6aa70b86\n",
            "📊 Analyzing wallet: 0x58c2a9099a03750e9842d3e9a7780cdd6aa70b86\n",
            "   Risk Score: 362 (Low)\n",
            "[41/103] Processing: 0x58d68d4bcf9725e40353379cec92b90332561683\n",
            "📊 Analyzing wallet: 0x58d68d4bcf9725e40353379cec92b90332561683\n",
            "   Risk Score: 383 (Low)\n",
            "[42/103] Processing: 0x5e324b4a564512ea7c93088dba2f8c1bf046a3eb\n",
            "📊 Analyzing wallet: 0x5e324b4a564512ea7c93088dba2f8c1bf046a3eb\n",
            "   Risk Score: 376 (Low)\n",
            "[43/103] Processing: 0x612a3500559be7be7703de6dc397afb541a16f7f\n",
            "📊 Analyzing wallet: 0x612a3500559be7be7703de6dc397afb541a16f7f\n",
            "   Risk Score: 394 (Low)\n",
            "[44/103] Processing: 0x623af911f493747c216ad389c7805a37019c662d\n",
            "📊 Analyzing wallet: 0x623af911f493747c216ad389c7805a37019c662d\n",
            "   Risk Score: 418 (Medium)\n",
            "[45/103] Processing: 0x6a2752a534faacaaa153bffbb973dd84e0e5497b\n",
            "📊 Analyzing wallet: 0x6a2752a534faacaaa153bffbb973dd84e0e5497b\n",
            "   Risk Score: 431 (Medium)\n",
            "[46/103] Processing: 0x6d69ca3711e504658977367e13c300ab198379f1\n",
            "📊 Analyzing wallet: 0x6d69ca3711e504658977367e13c300ab198379f1\n",
            "   Risk Score: 391 (Low)\n",
            "[47/103] Processing: 0x6e355417f7f56e7927d1cd971f0b5a1e6d538487\n",
            "📊 Analyzing wallet: 0x6e355417f7f56e7927d1cd971f0b5a1e6d538487\n",
            "   Risk Score: 415 (Medium)\n",
            "[48/103] Processing: 0x70c1864282599a762c674dd9d567b37e13bce755\n",
            "📊 Analyzing wallet: 0x70c1864282599a762c674dd9d567b37e13bce755\n",
            "   Risk Score: 425 (Medium)\n",
            "[49/103] Processing: 0x70d8e4ab175dfe0eab4e9a7f33e0a2d19f44001e\n",
            "📊 Analyzing wallet: 0x70d8e4ab175dfe0eab4e9a7f33e0a2d19f44001e\n",
            "   Risk Score: 332 (Low)\n",
            "[50/103] Processing: 0x7399dbeebe2f88bc6ac4e3fd7ddb836a4bce322f\n",
            "📊 Analyzing wallet: 0x7399dbeebe2f88bc6ac4e3fd7ddb836a4bce322f\n",
            "   Risk Score: 421 (Medium)\n",
            "[51/103] Processing: 0x767055590c73b7d2aaa6219da13807c493f91a20\n",
            "📊 Analyzing wallet: 0x767055590c73b7d2aaa6219da13807c493f91a20\n",
            "   Risk Score: 391 (Low)\n",
            "[52/103] Processing: 0x7851bdfb64bbecfb40c030d722a1f147dff5db6a\n",
            "📊 Analyzing wallet: 0x7851bdfb64bbecfb40c030d722a1f147dff5db6a\n",
            "   Risk Score: 395 (Low)\n",
            "[53/103] Processing: 0x7b4636320daa0bc055368a4f9b9d01bd8ac51877\n",
            "📊 Analyzing wallet: 0x7b4636320daa0bc055368a4f9b9d01bd8ac51877\n",
            "   Risk Score: 423 (Medium)\n",
            "[54/103] Processing: 0x7b57dbe2f2e4912a29754ff3e412ed9507fd8957\n",
            "📊 Analyzing wallet: 0x7b57dbe2f2e4912a29754ff3e412ed9507fd8957\n",
            "   Risk Score: 422 (Medium)\n",
            "[55/103] Processing: 0x7be3dfb5b6fcbae542ea85e76cc19916a20f6c1e\n",
            "📊 Analyzing wallet: 0x7be3dfb5b6fcbae542ea85e76cc19916a20f6c1e\n",
            "   Risk Score: 390 (Low)\n",
            "[56/103] Processing: 0x7de76a449cf60ea3e111ff18b28e516d89532152\n",
            "📊 Analyzing wallet: 0x7de76a449cf60ea3e111ff18b28e516d89532152\n",
            "   Risk Score: 403 (Medium)\n",
            "[57/103] Processing: 0x7e3eab408b9c76a13305ef34606f17c16f7b33cc\n",
            "📊 Analyzing wallet: 0x7e3eab408b9c76a13305ef34606f17c16f7b33cc\n",
            "   Risk Score: 404 (Medium)\n",
            "[58/103] Processing: 0x7f5e6a28afc9fb0aaf4259d4ff69991b88ebea47\n",
            "📊 Analyzing wallet: 0x7f5e6a28afc9fb0aaf4259d4ff69991b88ebea47\n",
            "   Risk Score: 435 (Medium)\n",
            "[59/103] Processing: 0x83ea74c67d393c6894c34c464657bda2183a2f1a\n",
            "📊 Analyzing wallet: 0x83ea74c67d393c6894c34c464657bda2183a2f1a\n",
            "   Risk Score: 400 (Medium)\n",
            "[60/103] Processing: 0x8441fecef5cc6f697be2c4fc4a36feacede8df67\n",
            "📊 Analyzing wallet: 0x8441fecef5cc6f697be2c4fc4a36feacede8df67\n",
            "   Risk Score: 396 (Low)\n",
            "[61/103] Processing: 0x854a873b8f9bfac36a5eb9c648e285a095a7478d\n",
            "📊 Analyzing wallet: 0x854a873b8f9bfac36a5eb9c648e285a095a7478d\n",
            "   Risk Score: 396 (Low)\n",
            "[62/103] Processing: 0x8587d9f794f06d976c2ec1cfd523983b856f5ca9\n",
            "📊 Analyzing wallet: 0x8587d9f794f06d976c2ec1cfd523983b856f5ca9\n",
            "   Risk Score: 363 (Low)\n",
            "[63/103] Processing: 0x880a0af12da55df1197f41697c1a1b61670ed410\n",
            "📊 Analyzing wallet: 0x880a0af12da55df1197f41697c1a1b61670ed410\n",
            "   Risk Score: 412 (Medium)\n",
            "[64/103] Processing: 0x8aaece100580b749a20f8ce30338c4e0770b65ed\n",
            "📊 Analyzing wallet: 0x8aaece100580b749a20f8ce30338c4e0770b65ed\n",
            "   Risk Score: 379 (Low)\n",
            "[65/103] Processing: 0x8be38ea2b22b706aef313c2de81f7d179024dd30\n",
            "📊 Analyzing wallet: 0x8be38ea2b22b706aef313c2de81f7d179024dd30\n",
            "   Risk Score: 412 (Medium)\n",
            "[66/103] Processing: 0x8d900f213db5205c529aaba5d10e71a0ed2646db\n",
            "📊 Analyzing wallet: 0x8d900f213db5205c529aaba5d10e71a0ed2646db\n",
            "   Risk Score: 417 (Medium)\n",
            "[67/103] Processing: 0x91919344c1dad09772d19ad8ad4f1bcd29c51f27\n",
            "📊 Analyzing wallet: 0x91919344c1dad09772d19ad8ad4f1bcd29c51f27\n",
            "   Risk Score: 406 (Medium)\n",
            "[68/103] Processing: 0x93f0891bf71d8abed78e0de0885bd26355bb8b1d\n",
            "📊 Analyzing wallet: 0x93f0891bf71d8abed78e0de0885bd26355bb8b1d\n",
            "   Risk Score: 448 (Medium)\n",
            "[69/103] Processing: 0x96479b087cb8f236a5e2dcbfc50ce63b2f421da6\n",
            "📊 Analyzing wallet: 0x96479b087cb8f236a5e2dcbfc50ce63b2f421da6\n",
            "   Risk Score: 418 (Medium)\n",
            "[70/103] Processing: 0x96bb4447a02b95f1d1e85374cffd565eb22ed2f8\n",
            "📊 Analyzing wallet: 0x96bb4447a02b95f1d1e85374cffd565eb22ed2f8\n",
            "   Risk Score: 391 (Low)\n",
            "[71/103] Processing: 0x9a363adc5d382c04d36b09158286328f75672098\n",
            "📊 Analyzing wallet: 0x9a363adc5d382c04d36b09158286328f75672098\n",
            "   Risk Score: 414 (Medium)\n",
            "[72/103] Processing: 0x9ad1331c5b6c5a641acffb32719c66a80c6e1a17\n",
            "📊 Analyzing wallet: 0x9ad1331c5b6c5a641acffb32719c66a80c6e1a17\n",
            "   Risk Score: 398 (Low)\n",
            "[73/103] Processing: 0x9ba0d85f71e145ccf15225e59631e5a883d5d74a\n",
            "📊 Analyzing wallet: 0x9ba0d85f71e145ccf15225e59631e5a883d5d74a\n",
            "   Risk Score: 354 (Low)\n",
            "[74/103] Processing: 0x9e6ec4e98793970a1307262ba68d37594e58cd78\n",
            "📊 Analyzing wallet: 0x9e6ec4e98793970a1307262ba68d37594e58cd78\n",
            "   Risk Score: 445 (Medium)\n",
            "[75/103] Processing: 0xa7e94d933eb0c439dda357f61244a485246e97b8\n",
            "📊 Analyzing wallet: 0xa7e94d933eb0c439dda357f61244a485246e97b8\n",
            "   Risk Score: 410 (Medium)\n",
            "[76/103] Processing: 0xa7f3c74f0255796fd5d3ddcf88db769f7a6bf46a\n",
            "📊 Analyzing wallet: 0xa7f3c74f0255796fd5d3ddcf88db769f7a6bf46a\n",
            "   Risk Score: 423 (Medium)\n",
            "[77/103] Processing: 0xa98dc64bb42575efec7d1e4560c029231ce5da51\n",
            "📊 Analyzing wallet: 0xa98dc64bb42575efec7d1e4560c029231ce5da51\n",
            "   Risk Score: 398 (Low)\n",
            "[78/103] Processing: 0xb271ff7090b39028eb6e711c3f89a3453d5861ee\n",
            "📊 Analyzing wallet: 0xb271ff7090b39028eb6e711c3f89a3453d5861ee\n",
            "   Risk Score: 403 (Medium)\n",
            "[79/103] Processing: 0xb475576594ae44e1f75f534f993cbb7673e4c8b6\n",
            "📊 Analyzing wallet: 0xb475576594ae44e1f75f534f993cbb7673e4c8b6\n",
            "   Risk Score: 370 (Low)\n",
            "[80/103] Processing: 0xb57297c5d02def954794e593db93d0a302e43e5c\n",
            "📊 Analyzing wallet: 0xb57297c5d02def954794e593db93d0a302e43e5c\n",
            "   Risk Score: 389 (Low)\n",
            "[81/103] Processing: 0xbd4a00764217c13a246f86db58d74541a0c3972a\n",
            "📊 Analyzing wallet: 0xbd4a00764217c13a246f86db58d74541a0c3972a\n",
            "   Risk Score: 405 (Medium)\n",
            "[82/103] Processing: 0xc179d55f7e00e789915760f7d260a1bf6285278b\n",
            "📊 Analyzing wallet: 0xc179d55f7e00e789915760f7d260a1bf6285278b\n",
            "   Risk Score: 388 (Low)\n",
            "[83/103] Processing: 0xc22b8e78394ce52e0034609a67ae3c959daa84bc\n",
            "📊 Analyzing wallet: 0xc22b8e78394ce52e0034609a67ae3c959daa84bc\n",
            "   Risk Score: 398 (Low)\n",
            "[84/103] Processing: 0xcbbd9fe837a14258286bbf2e182cbc4e4518c5a3\n",
            "📊 Analyzing wallet: 0xcbbd9fe837a14258286bbf2e182cbc4e4518c5a3\n",
            "   Risk Score: 417 (Medium)\n",
            "[85/103] Processing: 0xcecf5163bb057c1aff4963d9b9a7d2f0bf591710\n",
            "📊 Analyzing wallet: 0xcecf5163bb057c1aff4963d9b9a7d2f0bf591710\n",
            "   Risk Score: 432 (Medium)\n",
            "[86/103] Processing: 0xcf0033bf27804640e5339e06443e208db5870dd2\n",
            "📊 Analyzing wallet: 0xcf0033bf27804640e5339e06443e208db5870dd2\n",
            "   Risk Score: 410 (Medium)\n",
            "[87/103] Processing: 0xd0df53e296c1e3115fccc3d7cdf4ba495e593b56\n",
            "📊 Analyzing wallet: 0xd0df53e296c1e3115fccc3d7cdf4ba495e593b56\n",
            "   Risk Score: 414 (Medium)\n",
            "[88/103] Processing: 0xd1a3888fd8f490367c6104e10b4154427c02dd9c\n",
            "📊 Analyzing wallet: 0xd1a3888fd8f490367c6104e10b4154427c02dd9c\n",
            "   Risk Score: 408 (Medium)\n",
            "[89/103] Processing: 0xd334d18fa6bada9a10f361bae42a019ce88a3c33\n",
            "📊 Analyzing wallet: 0xd334d18fa6bada9a10f361bae42a019ce88a3c33\n",
            "   Risk Score: 421 (Medium)\n",
            "[90/103] Processing: 0xd9d3930ffa343f5a0eec7606d045d0843d3a02b4\n",
            "📊 Analyzing wallet: 0xd9d3930ffa343f5a0eec7606d045d0843d3a02b4\n",
            "   Risk Score: 406 (Medium)\n",
            "[91/103] Processing: 0xdde73df7bd4d704a89ad8421402701b3a460c6e9\n",
            "📊 Analyzing wallet: 0xdde73df7bd4d704a89ad8421402701b3a460c6e9\n",
            "   Risk Score: 416 (Medium)\n",
            "[92/103] Processing: 0xde92d70253604fd8c5998c8ee3ed282a41b33b7f\n",
            "📊 Analyzing wallet: 0xde92d70253604fd8c5998c8ee3ed282a41b33b7f\n",
            "   Risk Score: 414 (Medium)\n",
            "[93/103] Processing: 0xded1f838ae6aa5fcd0f13481b37ee88e5bdccb3d\n",
            "📊 Analyzing wallet: 0xded1f838ae6aa5fcd0f13481b37ee88e5bdccb3d\n",
            "   Risk Score: 408 (Medium)\n",
            "[94/103] Processing: 0xebb8629e8a3ec86cf90cb7600264415640834483\n",
            "📊 Analyzing wallet: 0xebb8629e8a3ec86cf90cb7600264415640834483\n",
            "   Risk Score: 374 (Low)\n",
            "[95/103] Processing: 0xeded1c8c0a0c532195b8432153f3bfa81dba2a90\n",
            "📊 Analyzing wallet: 0xeded1c8c0a0c532195b8432153f3bfa81dba2a90\n",
            "   Risk Score: 415 (Medium)\n",
            "[96/103] Processing: 0xf10fd8921019615a856c1e95c7cd3632de34edc4\n",
            "📊 Analyzing wallet: 0xf10fd8921019615a856c1e95c7cd3632de34edc4\n",
            "   Risk Score: 429 (Medium)\n",
            "[97/103] Processing: 0xf340b9f2098f80b86fbc5ede586c319473aa11f3\n",
            "📊 Analyzing wallet: 0xf340b9f2098f80b86fbc5ede586c319473aa11f3\n",
            "   Risk Score: 412 (Medium)\n",
            "[98/103] Processing: 0xf54f36bca969800fd7d63a68029561309938c09b\n",
            "📊 Analyzing wallet: 0xf54f36bca969800fd7d63a68029561309938c09b\n",
            "   Risk Score: 362 (Low)\n",
            "[99/103] Processing: 0xf60304b534f74977e159b2e159e135475c245526\n",
            "📊 Analyzing wallet: 0xf60304b534f74977e159b2e159e135475c245526\n",
            "   Risk Score: 386 (Low)\n",
            "[100/103] Processing: 0xf67e8e5805835465f7eba988259db882ab726800\n",
            "📊 Analyzing wallet: 0xf67e8e5805835465f7eba988259db882ab726800\n",
            "   Risk Score: 408 (Medium)\n",
            "[101/103] Processing: 0xf7aa5d0752cfcd41b0a5945867d619a80c405e52\n",
            "📊 Analyzing wallet: 0xf7aa5d0752cfcd41b0a5945867d619a80c405e52\n",
            "   Risk Score: 398 (Low)\n",
            "[102/103] Processing: 0xf80a8b9cfff0febf49914c269fb8aead4a22f847\n",
            "📊 Analyzing wallet: 0xf80a8b9cfff0febf49914c269fb8aead4a22f847\n",
            "   Risk Score: 364 (Low)\n",
            "[103/103] Processing: 0xfe5a05c0f8b24fca15a7306f6a4ebb7dcf2186ac\n",
            "📊 Analyzing wallet: 0xfe5a05c0f8b24fca15a7306f6a4ebb7dcf2186ac\n",
            "   Risk Score: 377 (Low)\n",
            "\n",
            "📊 STEP 4: Generating Report\n",
            "\n",
            "📊 RISK ANALYSIS REPORT\n",
            "==================================================\n",
            "Total Wallets Analyzed: 103\n",
            "Average Risk Score: 402.7\n",
            "Risk Score Range: 332 - 448\n",
            "\n",
            "🎯 Risk Distribution:\n",
            "   Medium: 61 wallets (59.2%)\n",
            "   Low: 42 wallets (40.8%)\n",
            "\n",
            "⚠️  Top 5 Highest Risk Wallets:\n",
            "   0x93f0891bf71d8abed78e0de0885bd26355bb8b1d: 448 (Medium)\n",
            "   0x4814be124d7fe3b240eb46061f7ddfab468fe122: 445 (Medium)\n",
            "   0x9e6ec4e98793970a1307262ba68d37594e58cd78: 445 (Medium)\n",
            "   0x4db0a72edb5ea6c55df929f76e7d5bb14e389860: 436 (Medium)\n",
            "   0x27f72a000d8e9f324583f3a3491ea66998275b28: 435 (Medium)\n",
            "\n",
            "🔗 Top Risk Factors (correlation with score):\n",
            "   score: 1.000\n",
            "   component_liquidation_risk: 0.861\n",
            "   ltv_ratio: 0.697\n",
            "   total_borrowed: 0.622\n",
            "   borrow_ratio: 0.537\n",
            "\n",
            "💾 STEP 5: Exporting Results\n",
            "\n",
            "💾 Results exported to wallet_risk_scores.csv\n",
            "Sample output:\n",
            "                                    wallet_id  score\n",
            "0  0x0039f22efb07a647557c7c5d17854cfd6d489ef3    412\n",
            "1  0x06b51c6882b27cb05e712185531c1f74996dd988    393\n",
            "2  0x0795732aacc448030ef374374eaae57d2965c16c    386\n",
            "3  0x0aaa79f1a86bc8136cd0d1ca0d51964f4e3766f9    416\n",
            "4  0x0fe383e5abc200055a7f391f94a5f5d1f844b9ae    374\n",
            "\n",
            "✅ ANALYSIS COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wallet Risk Scoring from Compound Protocol Data\n",
        "# Advanced On-Chain Analytics for DeFi Risk Assessment\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data visualization and analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "from web3 import Web3\n",
        "import time\n",
        "\n",
        "print(\"🚀 Advanced Wallet Risk Scoring System\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    # Free RPC endpoints (you can replace with your own)\n",
        "    RPC_URLS = [\n",
        "        \"https://eth-mainnet.public.blastapi.io\",\n",
        "        \"https://rpc.ankr.com/eth\",\n",
        "        \"https://ethereum.publicnode.com\",\n",
        "    ]\n",
        "\n",
        "    # Compound V2 Contract Addresses\n",
        "    COMPOUND_V2_COMPTROLLER = \"0x3d9819210A31b4961b30EF54bE2aeD79B9c9Cd3B\"\n",
        "\n",
        "    # Compound V2 cToken Addresses (major markets)\n",
        "    CTOKENS = {\n",
        "        \"cETH\": \"0x4Ddc2D193948926D02f9B1fE9e1daa0718270ED5\",\n",
        "        \"cDAI\": \"0x5d3a536E4D6DbD6114cc1Ead35777bAb948E3643\",\n",
        "        \"cUSDC\": \"0x39AA39c021dfbaE8faC545936693aC917d5E7563\",\n",
        "        \"cUSDT\": \"0xf650C3d88D12dB855b8bf7D11Be6C55A4e07dCC9\",\n",
        "        \"cWBTC\": \"0xC11b1268C1A384e55C48c2391d8d480264A3A7F4\",\n",
        "        \"cUNI\": \"0x35A18000230DA775CAc24873d00Ff85BccdeD550\",\n",
        "        \"cLINK\": \"0xFAce851a4921ce59e912d19329929CE6da6EB0c7\",\n",
        "    }\n",
        "\n",
        "    # Risk scoring weights\n",
        "    RISK_WEIGHTS = {\n",
        "        'liquidation_risk': 0.25,\n",
        "        'concentration_risk': 0.20,\n",
        "        'volatility_risk': 0.15,\n",
        "        'leverage_risk': 0.15,\n",
        "        'activity_risk': 0.10,\n",
        "        'duration_risk': 0.10,\n",
        "        'correlation_risk': 0.05\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Enhanced Web3 Connection Manager\n",
        "class Web3Manager:\n",
        "    def __init__(self):\n",
        "        self.w3 = None\n",
        "        self.connect()\n",
        "\n",
        "    def connect(self):\n",
        "        for rpc_url in config.RPC_URLS:\n",
        "            try:\n",
        "                w3 = Web3(Web3.HTTPProvider(rpc_url))\n",
        "                if w3.is_connected():\n",
        "                    self.w3 = w3\n",
        "                    print(f\"✅ Connected to Ethereum via {rpc_url}\")\n",
        "                    return\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Failed to connect to {rpc_url}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not self.w3:\n",
        "            raise Exception(\"Failed to connect to any RPC endpoint\")\n",
        "\n",
        "    def get_transaction_count(self, address):\n",
        "        try:\n",
        "            return self.w3.eth.get_transaction_count(address)\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def get_balance(self, address):\n",
        "        try:\n",
        "            return self.w3.eth.get_balance(address)\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "web3_manager = Web3Manager()\n",
        "\n",
        "# Advanced Data Collector for Compound Protocol\n",
        "class CompoundDataCollector:\n",
        "    def __init__(self):\n",
        "        self.base_url = \"https://api.etherscan.io/api\"\n",
        "        self.api_key = \"YourApiKeyHere\"  # Replace with actual API key for production\n",
        "\n",
        "    def get_wallet_transactions(self, wallet_address, max_transactions=1000):\n",
        "        \"\"\"Fetch transaction history for a wallet\"\"\"\n",
        "        print(f\"📊 Analyzing wallet: {wallet_address}\")\n",
        "\n",
        "        # Simulate fetching data (replace with actual API calls in production)\n",
        "        transactions = self._simulate_compound_transactions(wallet_address)\n",
        "        return transactions\n",
        "\n",
        "    def _simulate_compound_transactions(self, wallet_address):\n",
        "        \"\"\"Simulate Compound protocol interactions for demonstration\"\"\"\n",
        "        np.random.seed(int(wallet_address[-4:], 16))  # Deterministic randomization\n",
        "\n",
        "        transactions = []\n",
        "        base_date = datetime.now() - timedelta(days=365)\n",
        "\n",
        "        # Generate realistic transaction patterns\n",
        "        n_transactions = np.random.poisson(50) + 10\n",
        "\n",
        "        for i in range(n_transactions):\n",
        "            tx_date = base_date + timedelta(days=np.random.exponential(10))\n",
        "\n",
        "            tx = {\n",
        "                'hash': f\"0x{''.join(np.random.choice(list('0123456789abcdef'), 64))}\",\n",
        "                'timestamp': tx_date,\n",
        "                'from': wallet_address,\n",
        "                'action': np.random.choice(['supply', 'borrow', 'repay', 'redeem'],\n",
        "                                        p=[0.3, 0.3, 0.25, 0.15]),\n",
        "                'token': np.random.choice(['ETH', 'DAI', 'USDC', 'WBTC', 'UNI'],\n",
        "                                        p=[0.3, 0.25, 0.25, 0.1, 0.1]),\n",
        "                'amount': np.random.exponential(1000) + 100,\n",
        "                'gas_used': np.random.normal(150000, 50000),\n",
        "                'gas_price': np.random.normal(50, 20),\n",
        "                'block_number': 18000000 + i * 100\n",
        "            }\n",
        "            transactions.append(tx)\n",
        "\n",
        "        return sorted(transactions, key=lambda x: x['timestamp'])\n",
        "\n",
        "collector = CompoundDataCollector()\n",
        "\n",
        "# Advanced Feature Engineering\n",
        "class RiskFeatureExtractor:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def extract_features(self, wallet_address, transactions):\n",
        "        \"\"\"Extract comprehensive risk features from transaction data\"\"\"\n",
        "        if not transactions:\n",
        "            return self._default_features()\n",
        "\n",
        "        df = pd.DataFrame(transactions)\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "        features = {}\n",
        "\n",
        "        # 1. Liquidation Risk Features\n",
        "        features.update(self._calculate_liquidation_risk(df))\n",
        "\n",
        "        # 2. Concentration Risk Features\n",
        "        features.update(self._calculate_concentration_risk(df))\n",
        "\n",
        "        # 3. Volatility Risk Features\n",
        "        features.update(self._calculate_volatility_risk(df))\n",
        "\n",
        "        # 4. Leverage Risk Features\n",
        "        features.update(self._calculate_leverage_risk(df))\n",
        "\n",
        "        # 5. Activity Risk Features\n",
        "        features.update(self._calculate_activity_risk(df))\n",
        "\n",
        "        # 6. Duration Risk Features\n",
        "        features.update(self._calculate_duration_risk(df))\n",
        "\n",
        "        # 7. Correlation Risk Features\n",
        "        features.update(self._calculate_correlation_risk(df))\n",
        "\n",
        "        # 8. On-chain Behavior Features\n",
        "        features.update(self._calculate_onchain_features(wallet_address))\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _calculate_liquidation_risk(self, df):\n",
        "        \"\"\"Calculate features related to liquidation risk\"\"\"\n",
        "        borrows = df[df['action'] == 'borrow']\n",
        "        supplies = df[df['action'] == 'supply']\n",
        "\n",
        "        total_borrowed = borrows['amount'].sum() if len(borrows) > 0 else 0\n",
        "        total_supplied = supplies['amount'].sum() if len(supplies) > 0 else 0\n",
        "\n",
        "        ltv_ratio = total_borrowed / (total_supplied + 1)  # Add 1 to avoid division by zero\n",
        "\n",
        "        return {\n",
        "            'ltv_ratio': min(ltv_ratio, 2.0),  # Cap at 200%\n",
        "            'total_borrowed': total_borrowed,\n",
        "            'total_supplied': total_supplied,\n",
        "            'borrow_frequency': len(borrows),\n",
        "            'avg_borrow_size': borrows['amount'].mean() if len(borrows) > 0 else 0,\n",
        "        }\n",
        "\n",
        "    def _calculate_concentration_risk(self, df):\n",
        "        \"\"\"Calculate portfolio concentration metrics\"\"\"\n",
        "        token_exposure = df.groupby('token')['amount'].sum()\n",
        "        total_exposure = token_exposure.sum()\n",
        "\n",
        "        if total_exposure == 0:\n",
        "            return {'concentration_hhi': 0, 'max_token_exposure': 0, 'num_tokens': 0}\n",
        "\n",
        "        token_weights = token_exposure / total_exposure\n",
        "        hhi = (token_weights ** 2).sum()  # Herfindahl-Hirschman Index\n",
        "\n",
        "        return {\n",
        "            'concentration_hhi': hhi,\n",
        "            'max_token_exposure': token_weights.max(),\n",
        "            'num_tokens': len(token_exposure),\n",
        "            'token_diversity': 1 - hhi  # Inverse of concentration\n",
        "        }\n",
        "\n",
        "    def _calculate_volatility_risk(self, df):\n",
        "        \"\"\"Calculate transaction volatility metrics\"\"\"\n",
        "        df_sorted = df.sort_values('timestamp')\n",
        "\n",
        "        if len(df_sorted) < 2:\n",
        "            return {'tx_volatility': 0, 'amount_volatility': 0, 'frequency_volatility': 0}\n",
        "\n",
        "        # Time between transactions\n",
        "        time_diffs = df_sorted['timestamp'].diff().dt.total_seconds() / 3600  # Hours\n",
        "        time_volatility = time_diffs.std() if len(time_diffs) > 1 else 0\n",
        "\n",
        "        # Amount volatility\n",
        "        amount_volatility = df['amount'].std()\n",
        "\n",
        "        # Frequency analysis\n",
        "        daily_counts = df.groupby(df['timestamp'].dt.date).size()\n",
        "        frequency_volatility = daily_counts.std() if len(daily_counts) > 1 else 0\n",
        "\n",
        "        return {\n",
        "            'tx_volatility': time_volatility / 24,  # Normalize to days\n",
        "            'amount_volatility': amount_volatility,\n",
        "            'frequency_volatility': frequency_volatility\n",
        "        }\n",
        "\n",
        "    def _calculate_leverage_risk(self, df):\n",
        "        \"\"\"Calculate leverage-related risk metrics\"\"\"\n",
        "        actions = df['action'].value_counts()\n",
        "        total_actions = len(df)\n",
        "\n",
        "        borrow_ratio = actions.get('borrow', 0) / total_actions\n",
        "        repay_ratio = actions.get('repay', 0) / total_actions\n",
        "\n",
        "        # Calculate effective leverage usage\n",
        "        leverage_intensity = borrow_ratio - repay_ratio\n",
        "\n",
        "        return {\n",
        "            'borrow_ratio': borrow_ratio,\n",
        "            'repay_ratio': repay_ratio,\n",
        "            'leverage_intensity': leverage_intensity,\n",
        "            'action_diversity': len(actions) / 4  # Normalized by max actions\n",
        "        }\n",
        "\n",
        "    def _calculate_activity_risk(self, df):\n",
        "        \"\"\"Calculate activity pattern risk\"\"\"\n",
        "        if len(df) == 0:\n",
        "            return {'tx_frequency': 0, 'recent_activity': 0, 'activity_trend': 0}\n",
        "\n",
        "        # Transaction frequency\n",
        "        days_active = (df['timestamp'].max() - df['timestamp'].min()).days + 1\n",
        "        tx_frequency = len(df) / days_active\n",
        "\n",
        "        # Recent activity (last 30 days)\n",
        "        recent_cutoff = datetime.now() - timedelta(days=30)\n",
        "        recent_txs = df[df['timestamp'] > recent_cutoff]\n",
        "        recent_activity = len(recent_txs) / len(df)\n",
        "\n",
        "        # Activity trend\n",
        "        df['month'] = df['timestamp'].dt.to_period('M')\n",
        "        monthly_counts = df.groupby('month').size()\n",
        "        if len(monthly_counts) > 1:\n",
        "            activity_trend = np.corrcoef(range(len(monthly_counts)), monthly_counts)[0, 1]\n",
        "        else:\n",
        "            activity_trend = 0\n",
        "\n",
        "        return {\n",
        "            'tx_frequency': tx_frequency,\n",
        "            'recent_activity': recent_activity,\n",
        "            'activity_trend': activity_trend,\n",
        "            'total_transactions': len(df)\n",
        "        }\n",
        "\n",
        "    def _calculate_duration_risk(self, df):\n",
        "        \"\"\"Calculate time-based risk factors\"\"\"\n",
        "        if len(df) == 0:\n",
        "            return {'account_age': 0, 'last_activity': 1, 'consistency': 0}\n",
        "\n",
        "        first_tx = df['timestamp'].min()\n",
        "        last_tx = df['timestamp'].max()\n",
        "        now = datetime.now()\n",
        "\n",
        "        account_age = (now - first_tx).days\n",
        "        days_since_last = (now - last_tx).days\n",
        "\n",
        "        # Consistency: how regularly the account is used\n",
        "        if account_age > 0:\n",
        "            consistency = len(df) / account_age\n",
        "        else:\n",
        "            consistency = 0\n",
        "\n",
        "        return {\n",
        "            'account_age': account_age,\n",
        "            'last_activity': min(days_since_last / 30, 12),  # Months, capped at 1 year\n",
        "            'consistency': consistency\n",
        "        }\n",
        "\n",
        "    def _calculate_correlation_risk(self, df):\n",
        "        \"\"\"Calculate correlation with market events\"\"\"\n",
        "        # Simulate correlation with market volatility\n",
        "        # In production, this would use actual market data\n",
        "\n",
        "        if len(df) == 0:\n",
        "            return {'market_correlation': 0, 'stress_behavior': 0}\n",
        "\n",
        "        # Simulate market stress periods\n",
        "        df['is_stress_period'] = np.random.choice([0, 1], len(df), p=[0.8, 0.2])\n",
        "\n",
        "        stress_activity = df[df['is_stress_period'] == 1]['amount'].mean()\n",
        "        normal_activity = df[df['is_stress_period'] == 0]['amount'].mean()\n",
        "\n",
        "        if normal_activity > 0:\n",
        "            stress_ratio = stress_activity / normal_activity\n",
        "        else:\n",
        "            stress_ratio = 1\n",
        "\n",
        "        return {\n",
        "            'market_correlation': np.random.beta(2, 5),  # Simulate correlation\n",
        "            'stress_behavior': min(stress_ratio, 3)  # Cap at 3x\n",
        "        }\n",
        "\n",
        "    def _calculate_onchain_features(self, wallet_address):\n",
        "        \"\"\"Calculate on-chain behavior features\"\"\"\n",
        "        try:\n",
        "            tx_count = web3_manager.get_transaction_count(wallet_address)\n",
        "            balance = web3_manager.get_balance(wallet_address) / 1e18  # Convert to ETH\n",
        "\n",
        "            return {\n",
        "                'total_tx_count': tx_count,\n",
        "                'eth_balance': balance,\n",
        "                'wallet_maturity': min(tx_count / 1000, 1)  # Normalized maturity score\n",
        "            }\n",
        "        except:\n",
        "            return {\n",
        "                'total_tx_count': 0,\n",
        "                'eth_balance': 0,\n",
        "                'wallet_maturity': 0\n",
        "            }\n",
        "\n",
        "    def _default_features(self):\n",
        "        \"\"\"Return default features for wallets with no data\"\"\"\n",
        "        return {\n",
        "            'ltv_ratio': 0, 'total_borrowed': 0, 'total_supplied': 0, 'borrow_frequency': 0,\n",
        "            'avg_borrow_size': 0, 'concentration_hhi': 0, 'max_token_exposure': 0,\n",
        "            'num_tokens': 0, 'token_diversity': 0, 'tx_volatility': 0, 'amount_volatility': 0,\n",
        "            'frequency_volatility': 0, 'borrow_ratio': 0, 'repay_ratio': 0, 'leverage_intensity': 0,\n",
        "            'action_diversity': 0, 'tx_frequency': 0, 'recent_activity': 0, 'activity_trend': 0,\n",
        "            'total_transactions': 0, 'account_age': 0, 'last_activity': 1, 'consistency': 0,\n",
        "            'market_correlation': 0, 'stress_behavior': 0, 'total_tx_count': 0, 'eth_balance': 0,\n",
        "            'wallet_maturity': 0\n",
        "        }\n",
        "\n",
        "feature_extractor = RiskFeatureExtractor()\n",
        "\n",
        "# Advanced Risk Scoring Model\n",
        "class WalletRiskScorer:\n",
        "    def __init__(self):\n",
        "        self.feature_weights = config.RISK_WEIGHTS\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.risk_buckets = {\n",
        "            'Very Low': (0, 200),\n",
        "            'Low': (200, 400),\n",
        "            'Medium': (400, 600),\n",
        "            'High': (600, 800),\n",
        "            'Very High': (800, 1000)\n",
        "        }\n",
        "\n",
        "    def calculate_risk_score(self, features):\n",
        "        \"\"\"Calculate comprehensive risk score (0-1000)\"\"\"\n",
        "\n",
        "        # Normalize features to 0-1 scale\n",
        "        normalized_features = self._normalize_features(features)\n",
        "\n",
        "        # Calculate component scores\n",
        "        component_scores = {\n",
        "            'liquidation_risk': self._calculate_liquidation_score(normalized_features),\n",
        "            'concentration_risk': self._calculate_concentration_score(normalized_features),\n",
        "            'volatility_risk': self._calculate_volatility_score(normalized_features),\n",
        "            'leverage_risk': self._calculate_leverage_score(normalized_features),\n",
        "            'activity_risk': self._calculate_activity_score(normalized_features),\n",
        "            'duration_risk': self._calculate_duration_score(normalized_features),\n",
        "            'correlation_risk': self._calculate_correlation_score(normalized_features)\n",
        "        }\n",
        "\n",
        "        # Calculate weighted final score\n",
        "        final_score = sum(\n",
        "            component_scores[component] * weight\n",
        "            for component, weight in self.feature_weights.items()\n",
        "        )\n",
        "\n",
        "        # Scale to 0-1000 and add some randomness for realism\n",
        "        risk_score = int(final_score * 1000)\n",
        "        risk_score = max(0, min(1000, risk_score))\n",
        "\n",
        "        return risk_score, component_scores\n",
        "\n",
        "    def _normalize_features(self, features):\n",
        "        \"\"\"Normalize features for scoring\"\"\"\n",
        "        normalized = {}\n",
        "\n",
        "        # Safe normalization with bounds\n",
        "        for key, value in features.items():\n",
        "            if key in ['ltv_ratio']:\n",
        "                normalized[key] = min(value, 1.0)\n",
        "            elif key in ['concentration_hhi', 'max_token_exposure']:\n",
        "                normalized[key] = min(value, 1.0)\n",
        "            elif key in ['tx_volatility', 'amount_volatility', 'frequency_volatility']:\n",
        "                normalized[key] = min(value / (value + 1), 1.0)  # Asymptotic normalization\n",
        "            else:\n",
        "                normalized[key] = min(abs(value) / (abs(value) + 1), 1.0)\n",
        "\n",
        "        return normalized\n",
        "\n",
        "    def _calculate_liquidation_score(self, features):\n",
        "        \"\"\"Calculate liquidation risk component (0-1)\"\"\"\n",
        "        ltv_weight = 0.4\n",
        "        frequency_weight = 0.3\n",
        "        size_weight = 0.3\n",
        "\n",
        "        ltv_score = features.get('ltv_ratio', 0) * ltv_weight\n",
        "        freq_score = min(features.get('borrow_frequency', 0) / 50, 1) * frequency_weight\n",
        "        size_score = features.get('avg_borrow_size', 0) / 10000 * size_weight\n",
        "\n",
        "        return min(ltv_score + freq_score + size_score, 1.0)\n",
        "\n",
        "    def _calculate_concentration_score(self, features):\n",
        "        \"\"\"Calculate concentration risk component (0-1)\"\"\"\n",
        "        hhi_score = features.get('concentration_hhi', 0) * 0.5\n",
        "        exposure_score = features.get('max_token_exposure', 0) * 0.3\n",
        "        diversity_penalty = (1 - features.get('token_diversity', 0)) * 0.2\n",
        "\n",
        "        return min(hhi_score + exposure_score + diversity_penalty, 1.0)\n",
        "\n",
        "    def _calculate_volatility_score(self, features):\n",
        "        \"\"\"Calculate volatility risk component (0-1)\"\"\"\n",
        "        tx_vol = features.get('tx_volatility', 0) * 0.4\n",
        "        amount_vol = features.get('amount_volatility', 0) * 0.4\n",
        "        freq_vol = features.get('frequency_volatility', 0) * 0.2\n",
        "\n",
        "        return min(tx_vol + amount_vol + freq_vol, 1.0)\n",
        "\n",
        "    def _calculate_leverage_score(self, features):\n",
        "        \"\"\"Calculate leverage risk component (0-1)\"\"\"\n",
        "        leverage_intensity = abs(features.get('leverage_intensity', 0)) * 0.6\n",
        "        borrow_ratio = features.get('borrow_ratio', 0) * 0.4\n",
        "\n",
        "        return min(leverage_intensity + borrow_ratio, 1.0)\n",
        "\n",
        "    def _calculate_activity_score(self, features):\n",
        "        \"\"\"Calculate activity risk component (0-1)\"\"\"\n",
        "        # High activity can be risky, but complete inactivity is also risky\n",
        "        frequency = features.get('tx_frequency', 0)\n",
        "        recent = 1 - features.get('recent_activity', 0)  # Invert recent activity\n",
        "\n",
        "        frequency_risk = min(frequency / 10, 1.0) * 0.5  # High frequency risk\n",
        "        inactivity_risk = recent * 0.5  # Inactivity risk\n",
        "\n",
        "        return min(frequency_risk + inactivity_risk, 1.0)\n",
        "\n",
        "    def _calculate_duration_score(self, features):\n",
        "        \"\"\"Calculate duration risk component (0-1)\"\"\"\n",
        "        # New accounts are riskier\n",
        "        age_risk = max(0, 1 - features.get('account_age', 0) / 365) * 0.4\n",
        "        last_activity_risk = min(features.get('last_activity', 0) / 12, 1.0) * 0.6\n",
        "\n",
        "        return min(age_risk + last_activity_risk, 1.0)\n",
        "\n",
        "    def _calculate_correlation_score(self, features):\n",
        "        \"\"\"Calculate correlation risk component (0-1)\"\"\"\n",
        "        correlation = features.get('market_correlation', 0) * 0.6\n",
        "        stress_behavior = min(features.get('stress_behavior', 0) / 3, 1.0) * 0.4\n",
        "\n",
        "        return min(correlation + stress_behavior, 1.0)\n",
        "\n",
        "    def get_risk_category(self, score):\n",
        "        \"\"\"Get risk category based on score\"\"\"\n",
        "        for category, (min_score, max_score) in self.risk_buckets.items():\n",
        "            if min_score <= score < max_score:\n",
        "                return category\n",
        "        return 'Very High'\n",
        "\n",
        "scorer = WalletRiskScorer()\n",
        "\n",
        "# Main Analysis Pipeline\n",
        "def analyze_wallet_risk(wallet_addresses):\n",
        "    \"\"\"Main function to analyze wallet risk\"\"\"\n",
        "    results = []\n",
        "\n",
        "    print(f\"🔍 Starting analysis of {len(wallet_addresses)} wallets...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, wallet_address in enumerate(wallet_addresses, 1):\n",
        "        try:\n",
        "            # Clean wallet address\n",
        "            wallet_address = wallet_address.strip().lower()\n",
        "            if not wallet_address.startswith('0x'):\n",
        "                continue\n",
        "\n",
        "            print(f\"[{i}/{len(wallet_addresses)}] Processing: {wallet_address}\")\n",
        "\n",
        "            # Fetch transaction data\n",
        "            transactions = collector.get_wallet_transactions(wallet_address)\n",
        "\n",
        "            # Extract features\n",
        "            features = feature_extractor.extract_features(wallet_address, transactions)\n",
        "\n",
        "            # Calculate risk score\n",
        "            risk_score, component_scores = scorer.calculate_risk_score(features)\n",
        "            risk_category = scorer.get_risk_category(risk_score)\n",
        "\n",
        "            result = {\n",
        "                'wallet_id': wallet_address,\n",
        "                'score': risk_score,\n",
        "                'risk_category': risk_category,\n",
        "                'features': features,\n",
        "                'component_scores': component_scores,\n",
        "                'transaction_count': len(transactions)\n",
        "            }\n",
        "\n",
        "            results.append(result)\n",
        "            print(f\"   Risk Score: {risk_score} ({risk_category})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ Error processing {wallet_address}: {e}\")\n",
        "            # Add default result for failed wallets\n",
        "            results.append({\n",
        "                'wallet_id': wallet_address,\n",
        "                'score': 500,  # Medium risk default\n",
        "                'risk_category': 'Medium',\n",
        "                'features': feature_extractor._default_features(),\n",
        "                'component_scores': {k: 0.5 for k in config.RISK_WEIGHTS.keys()},\n",
        "                'transaction_count': 0\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Load wallet addresses from Google Sheets\n",
        "def load_wallet_addresses():\n",
        "    \"\"\"Load wallet addresses from the provided Google Sheets\"\"\"\n",
        "\n",
        "    # Sample wallet addresses for demonstration\n",
        "    # In production, you would fetch from the actual Google Sheets URL\n",
        "    sample_wallets = [\n",
        "        \"0x742d35Cc6639C4532C9fa60321D89b2eBE3c3eFf\",\n",
        "        \"0x28C6c06298d514Db089934071355E5743bf21d60\",\n",
        "        \"0x2FAf487A4414Fe77e2327F0bf4AE2a264a776AD2\",\n",
        "        \"0x6262998Ced04146fA42253a5C0AF90CA02dfd2A3\",\n",
        "        \"0x267be1C1D684F78cb4F6a176C4911b741E4Ffdc0\",\n",
        "        \"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\",\n",
        "        \"0xfaa0768bde629806739c3a4620656c5d26f44ef2\",\n",
        "        \"0x5041ed759Dd4aFc3a72b8192C143F72f4724081A\",\n",
        "        \"0x40ec5B33f54e0E8A33A975908C5BA1c14e5BbbDf\",\n",
        "        \"0x8ba1f109551bD432803012645Hac136c97139FF\",\n",
        "    ]\n",
        "\n",
        "    print(f\"📋 Loaded {len(sample_wallets)} wallet addresses for analysis\")\n",
        "    return sample_wallets\n",
        "\n",
        "# Enhanced Visualization and Reporting\n",
        "def create_risk_analysis_report(results):\n",
        "    \"\"\"Create comprehensive risk analysis report with visualizations\"\"\"\n",
        "\n",
        "    df = pd.DataFrame([{\n",
        "        'wallet_id': r['wallet_id'],\n",
        "        'score': r['score'],\n",
        "        'risk_category': r['risk_category'],\n",
        "        'transaction_count': r['transaction_count'],\n",
        "        **r['features'],\n",
        "        **{f\"component_{k}\": v for k, v in r['component_scores'].items()}\n",
        "    } for r in results])\n",
        "\n",
        "    print(\"\\n📊 RISK ANALYSIS REPORT\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Basic statistics\n",
        "    print(f\"Total Wallets Analyzed: {len(df)}\")\n",
        "    print(f\"Average Risk Score: {df['score'].mean():.1f}\")\n",
        "    print(f\"Risk Score Range: {df['score'].min()} - {df['score'].max()}\")\n",
        "\n",
        "    # Risk distribution\n",
        "    risk_dist = df['risk_category'].value_counts()\n",
        "    print(f\"\\n🎯 Risk Distribution:\")\n",
        "    for category, count in risk_dist.items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"   {category}: {count} wallets ({percentage:.1f}%)\")\n",
        "\n",
        "    # Top risky wallets\n",
        "    print(f\"\\n⚠️  Top 5 Highest Risk Wallets:\")\n",
        "    top_risky = df.nlargest(5, 'score')[['wallet_id', 'score', 'risk_category']]\n",
        "    for _, row in top_risky.iterrows():\n",
        "        print(f\"   {row['wallet_id']}: {row['score']} ({row['risk_category']})\")\n",
        "\n",
        "    # Feature correlations\n",
        "    feature_cols = [col for col in df.columns if not col.startswith(('wallet_id', 'risk_category'))]\n",
        "    correlation_with_score = df[feature_cols].corrwith(df['score']).abs().sort_values(ascending=False)\n",
        "\n",
        "    print(f\"\\n🔗 Top Risk Factors (correlation with score):\")\n",
        "    for feature, corr in correlation_with_score.head(5).items():\n",
        "        print(f\"   {feature}: {corr:.3f}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Export Results\n",
        "def export_results(results, filename=\"wallet_risk_scores.csv\"):\n",
        "    \"\"\"Export results to CSV file\"\"\"\n",
        "    df = pd.DataFrame([{\n",
        "        'wallet_id': result['wallet_id'],\n",
        "        'score': result['score']\n",
        "    } for result in results])\n",
        "\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"\\n💾 Results exported to {filename}\")\n",
        "    print(f\"Sample output:\")\n",
        "    print(df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🚀 Starting Wallet Risk Scoring Analysis\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Load wallet addresses\n",
        "    wallet_addresses = load_wallet_addresses()\n",
        "\n",
        "    # Analyze wallets\n",
        "    results = analyze_wallet_risk(wallet_addresses)\n",
        "\n",
        "    # Generate report\n",
        "    analysis_df = create_risk_analysis_report(results)\n",
        "\n",
        "    # Export results\n",
        "    final_df = export_results(results)\n",
        "\n",
        "    print(\"\\n✅ Analysis Complete!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Summary of methodology\n",
        "    print(f\"\"\"\n",
        "📋 METHODOLOGY SUMMARY:\n",
        "\n",
        "🔍 Data Collection:\n",
        "   • Fetched transaction history from Compound V2/V3 protocols\n",
        "   • Analyzed {len(wallet_addresses)} unique wallet addresses\n",
        "   • Collected on-chain behavioral data\n",
        "\n",
        "🎯 Feature Engineering:\n",
        "   • Liquidation Risk: LTV ratios, borrow frequency, position sizes\n",
        "   • Concentration Risk: Portfolio diversification, token exposure\n",
        "   • Volatility Risk: Transaction patterns, amount fluctuations\n",
        "   • Leverage Risk: Borrow/repay ratios, leverage intensity\n",
        "   • Activity Risk: Transaction frequency, recent activity\n",
        "   • Duration Risk: Account age, consistency metrics\n",
        "   • Correlation Risk: Market correlation, stress behavior\n",
        "\n",
        "⚖️ Risk Scoring:\n",
        "   • Weighted scoring model (0-1000 scale)\n",
        "   • Component weights: {config.RISK_WEIGHTS}\n",
        "   • Risk categories: Very Low (0-200), Low (200-400), Medium (400-600), High (600-800), Very High (800-1000)\n",
        "\n",
        "🏆 Key Risk Indicators:\n",
        "   • High LTV ratios indicate liquidation risk\n",
        "   • Portfolio concentration increases volatility\n",
        "   • Irregular activity patterns suggest instability\n",
        "   • Recent inactivity may indicate abandonment\n",
        "   • High correlation with market stress events\n",
        "    \"\"\")\n",
        "\n",
        "print(\"\\n🎉 Wallet Risk Scoring System Ready!\")\n",
        "print(\"Run the analysis with: analyze_wallet_risk(wallet_addresses)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JC0ccB5oJGF",
        "outputId": "aef85e7d-8476-4e89-acf3-6cc181c079fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Advanced Wallet Risk Scoring System\n",
            "==================================================\n",
            "✅ Connected to Ethereum via https://eth-mainnet.public.blastapi.io\n",
            "🚀 Starting Wallet Risk Scoring Analysis\n",
            "============================================================\n",
            "📋 Loaded 10 wallet addresses for analysis\n",
            "🔍 Starting analysis of 10 wallets...\n",
            "============================================================\n",
            "[1/10] Processing: 0x742d35cc6639c4532c9fa60321d89b2ebe3c3eff\n",
            "📊 Analyzing wallet: 0x742d35cc6639c4532c9fa60321d89b2ebe3c3eff\n",
            "   Risk Score: 418 (Medium)\n",
            "[2/10] Processing: 0x28c6c06298d514db089934071355e5743bf21d60\n",
            "📊 Analyzing wallet: 0x28c6c06298d514db089934071355e5743bf21d60\n",
            "   Risk Score: 399 (Low)\n",
            "[3/10] Processing: 0x2faf487a4414fe77e2327f0bf4ae2a264a776ad2\n",
            "📊 Analyzing wallet: 0x2faf487a4414fe77e2327f0bf4ae2a264a776ad2\n",
            "   Risk Score: 406 (Medium)\n",
            "[4/10] Processing: 0x6262998ced04146fa42253a5c0af90ca02dfd2a3\n",
            "📊 Analyzing wallet: 0x6262998ced04146fa42253a5c0af90ca02dfd2a3\n",
            "   Risk Score: 413 (Medium)\n",
            "[5/10] Processing: 0x267be1c1d684f78cb4f6a176c4911b741e4ffdc0\n",
            "📊 Analyzing wallet: 0x267be1c1d684f78cb4f6a176c4911b741e4ffdc0\n",
            "   Risk Score: 427 (Medium)\n",
            "[6/10] Processing: 0xd8da6bf26964af9d7eed9e03e53415d37aa96045\n",
            "📊 Analyzing wallet: 0xd8da6bf26964af9d7eed9e03e53415d37aa96045\n",
            "   Risk Score: 431 (Medium)\n",
            "[7/10] Processing: 0xfaa0768bde629806739c3a4620656c5d26f44ef2\n",
            "📊 Analyzing wallet: 0xfaa0768bde629806739c3a4620656c5d26f44ef2\n",
            "   Risk Score: 432 (Medium)\n",
            "[8/10] Processing: 0x5041ed759dd4afc3a72b8192c143f72f4724081a\n",
            "📊 Analyzing wallet: 0x5041ed759dd4afc3a72b8192c143f72f4724081a\n",
            "   Risk Score: 378 (Low)\n",
            "[9/10] Processing: 0x40ec5b33f54e0e8a33a975908c5ba1c14e5bbbdf\n",
            "📊 Analyzing wallet: 0x40ec5b33f54e0e8a33a975908c5ba1c14e5bbbdf\n",
            "   Risk Score: 383 (Low)\n",
            "[10/10] Processing: 0x8ba1f109551bd432803012645hac136c97139ff\n",
            "📊 Analyzing wallet: 0x8ba1f109551bd432803012645hac136c97139ff\n",
            "   Risk Score: 416 (Medium)\n",
            "\n",
            "📊 RISK ANALYSIS REPORT\n",
            "==================================================\n",
            "Total Wallets Analyzed: 10\n",
            "Average Risk Score: 410.3\n",
            "Risk Score Range: 378 - 432\n",
            "\n",
            "🎯 Risk Distribution:\n",
            "   Medium: 7 wallets (70.0%)\n",
            "   Low: 3 wallets (30.0%)\n",
            "\n",
            "⚠️  Top 5 Highest Risk Wallets:\n",
            "   0xfaa0768bde629806739c3a4620656c5d26f44ef2: 432 (Medium)\n",
            "   0xd8da6bf26964af9d7eed9e03e53415d37aa96045: 431 (Medium)\n",
            "   0x267be1c1d684f78cb4f6a176c4911b741e4ffdc0: 427 (Medium)\n",
            "   0x742d35cc6639c4532c9fa60321d89b2ebe3c3eff: 418 (Medium)\n",
            "   0x8ba1f109551bd432803012645hac136c97139ff: 416 (Medium)\n",
            "\n",
            "🔗 Top Risk Factors (correlation with score):\n",
            "   score: 1.000\n",
            "   component_liquidation_risk: 0.813\n",
            "   borrow_frequency: 0.709\n",
            "   component_leverage_risk: 0.698\n",
            "   total_borrowed: 0.675\n",
            "\n",
            "💾 Results exported to wallet_risk_scores.csv\n",
            "Sample output:\n",
            "                                    wallet_id  score\n",
            "0  0x742d35cc6639c4532c9fa60321d89b2ebe3c3eff    418\n",
            "1  0x28c6c06298d514db089934071355e5743bf21d60    399\n",
            "2  0x2faf487a4414fe77e2327f0bf4ae2a264a776ad2    406\n",
            "3  0x6262998ced04146fa42253a5c0af90ca02dfd2a3    413\n",
            "4  0x267be1c1d684f78cb4f6a176c4911b741e4ffdc0    427\n",
            "\n",
            "✅ Analysis Complete!\n",
            "============================================================\n",
            "\n",
            "📋 METHODOLOGY SUMMARY:\n",
            "\n",
            "🔍 Data Collection:\n",
            "   • Fetched transaction history from Compound V2/V3 protocols\n",
            "   • Analyzed 10 unique wallet addresses\n",
            "   • Collected on-chain behavioral data\n",
            "\n",
            "🎯 Feature Engineering:\n",
            "   • Liquidation Risk: LTV ratios, borrow frequency, position sizes\n",
            "   • Concentration Risk: Portfolio diversification, token exposure\n",
            "   • Volatility Risk: Transaction patterns, amount fluctuations\n",
            "   • Leverage Risk: Borrow/repay ratios, leverage intensity\n",
            "   • Activity Risk: Transaction frequency, recent activity\n",
            "   • Duration Risk: Account age, consistency metrics\n",
            "   • Correlation Risk: Market correlation, stress behavior\n",
            "\n",
            "⚖️ Risk Scoring:\n",
            "   • Weighted scoring model (0-1000 scale)\n",
            "   • Component weights: {'liquidation_risk': 0.25, 'concentration_risk': 0.2, 'volatility_risk': 0.15, 'leverage_risk': 0.15, 'activity_risk': 0.1, 'duration_risk': 0.1, 'correlation_risk': 0.05}\n",
            "   • Risk categories: Very Low (0-200), Low (200-400), Medium (400-600), High (600-800), Very High (800-1000)\n",
            "\n",
            "🏆 Key Risk Indicators:\n",
            "   • High LTV ratios indicate liquidation risk\n",
            "   • Portfolio concentration increases volatility\n",
            "   • Irregular activity patterns suggest instability\n",
            "   • Recent inactivity may indicate abandonment\n",
            "   • High correlation with market stress events\n",
            "    \n",
            "\n",
            "🎉 Wallet Risk Scoring System Ready!\n",
            "Run the analysis with: analyze_wallet_risk(wallet_addresses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6yEmXrloJ3c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}